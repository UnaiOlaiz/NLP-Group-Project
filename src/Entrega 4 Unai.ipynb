{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce21d82",
   "metadata": {},
   "source": [
    "# Generación de Versos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674c0ca",
   "metadata": {},
   "source": [
    "### Librerías Necearias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8edd2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893a7df",
   "metadata": {},
   "source": [
    "### Código de Clases + Funciones Necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5221afb",
   "metadata": {},
   "source": [
    "Clase Vocabulary (no es extrictamente necesaria), ya que la que después se usa es la del vocabulary especializado (con los tokens \\<UNK>, \\<MASK>, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c545a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = dict(token_to_idx)\n",
    "        self._idx_to_token = {idx: token for token, idx in self._token_to_idx.items()}\n",
    "\n",
    "    def to_serializable(self):\n",
    "        # función para serializar el diccionario token (label) - idx (int)\n",
    "        return {\"token_to_idx\": self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(token_to_idx=contents[\"token_to_idx\"])\n",
    "\n",
    "    def add_token(self, token):\n",
    "        # función para añadir token (nuevo) al diccionario\n",
    "        if token in self._token_to_idx:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "        index = len(self._token_to_idx)\n",
    "        self._token_to_idx[token] = index\n",
    "        self._idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_many_tokens(self, tokens):\n",
    "        # función para añadir N > 1 tokens al diccionario\n",
    "        return [self.add_token(t) for t in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        # función para obtener el idx del token introducido\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        # función para obtener el token del idx introducido\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # devuelve el tamaño del diccionario\n",
    "        return len(self._token_to_idx)\n",
    "\n",
    "    def __str__(self):\n",
    "        # devuelve el tamaño del vocabulario\n",
    "        return f\"<Vocabulary(size={len(self)})>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ecf5b",
   "metadata": {},
   "source": [
    "Vocabulary especial Corán con los tokens especiales \\<eos>, \\<bos>, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a45accb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabularyCoran(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super().__init__(token_to_idx)\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        # función para serializar el diccionario token (label) - idx (int)\n",
    "        contents = super().to_serializable()\n",
    "        contents.update({\n",
    "            \"unk_token\": self._unk_token,\n",
    "            \"mask_token\": self._mask_token,\n",
    "            \"begin_seq_token\": self._begin_seq_token,\n",
    "            \"end_seq_token\": self._end_seq_token\n",
    "        })\n",
    "        return contents\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        vocab = cls(\n",
    "            token_to_idx=contents[\"token_to_idx\"],\n",
    "            unk_token=contents[\"unk_token\"],\n",
    "            mask_token=contents[\"mask_token\"],\n",
    "            begin_seq_token=contents[\"begin_seq_token\"],\n",
    "            end_seq_token=contents[\"end_seq_token\"],\n",
    "        )\n",
    "        return vocab\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        # función para obtener el idx del token introducido\n",
    "        return self._token_to_idx.get(token, self.unk_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a364e89",
   "metadata": {},
   "source": [
    "Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf208cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoranVectorizer:\n",
    "    def __init__(self, char_vocab: VocabularyCoran):\n",
    "        self.char_vocab = char_vocab\n",
    "\n",
    "    def vectorize(self, text: str, vector_length: int):\n",
    "        indices = [self.char_vocab.begin_seq_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(ch) for ch in text)\n",
    "        indices.append(self.char_vocab.end_seq_index)\n",
    "\n",
    "        from_indices = indices[:-1]\n",
    "        to_indices = indices[1:]\n",
    "\n",
    "        # El from_vector será <bos> con los tokens de la secuencia (sin el <eos>)\n",
    "        from_vector = np.full(vector_length, fill_value=self.char_vocab.mask_index, dtype=np.int64)\n",
    "        # Y el to_vector será os tokens de la secuencia + <eos>\n",
    "        to_vector = np.full(vector_length, fill_value=self.char_vocab.mask_index, dtype=np.int64)\n",
    "\n",
    "        n = min(vector_length, len(from_indices))\n",
    "        from_vector[:n] = from_indices[:n]\n",
    "\n",
    "        n = min(vector_length, len(to_indices))\n",
    "        to_vector[:n] = to_indices[:n]\n",
    "\n",
    "        return from_vector, to_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df: pd.DataFrame, text_col=\"text\"):\n",
    "        char_vocab = VocabularyCoran()\n",
    "        for text in df[text_col].astype(str):\n",
    "            for ch in text:\n",
    "                char_vocab.add_token(ch)\n",
    "        return cls(char_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {\"char_vocab\": self.char_vocab.to_serializable()}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        char_vocab = VocabularyCoran.from_serializable(contents[\"char_vocab\"])\n",
    "        return cls(char_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5897a",
   "metadata": {},
   "source": [
    "Funciones para el entrenamiento (métricas de evaluación, argumentos de entrenamiento, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d52967e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, device, shuffle=True, drop_last=True):\n",
    "    # genera batches para mandarlos al cpu/gpu (si tenemos cuda)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    for batch in dataloader:\n",
    "        yield {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    # loss function, en nuestro caso el cross entropy loss. Ya que compararemos la distribución de predicciones con la ground truth\n",
    "    B, T, V = y_pred.shape\n",
    "    y_pred = y_pred.reshape(B * T, V)\n",
    "    y_true = y_true.reshape(B * T)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=mask_index)\n",
    "    return loss_fn(y_pred, y_true)\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    # función para calcular la accuracy, comparando cada caracter predicho con el ground truth\n",
    "    y_hat = y_pred.argmax(dim=-1)  \n",
    "    valid = (y_true != mask_index)\n",
    "    correct = (y_hat == y_true) & valid\n",
    "    denom = valid.sum().item()\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return correct.sum().item() / denom\n",
    "\n",
    "def make_train(args):\n",
    "    # sacado del notebook de ALUD, \n",
    "    return {\"stop_early\": False,\n",
    "            \"early_stopping_step\": 0,\n",
    "            \"early_stopping_best_val\": 1e8,\n",
    "            \"epoch_index\": 0,\n",
    "            \"train_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"val_acc\": [],\n",
    "            \"model_filename\": args.model_state_file}\n",
    "\n",
    "def update_training_state(args, model, train_state):\n",
    "    # función para tener en cuenta mejora/desmejora de rendimiento -> early_stopping\n",
    "    if train_state[\"epoch_index\"] == 0:\n",
    "        torch.save(model.state_dict(), train_state[\"model_filename\"])\n",
    "        train_state[\"stop_early\"] = False\n",
    "        return train_state\n",
    "\n",
    "    loss_t = train_state[\"val_loss\"][-1]\n",
    "    if loss_t < train_state[\"early_stopping_best_val\"]:\n",
    "        torch.save(model.state_dict(), train_state[\"model_filename\"])\n",
    "        train_state[\"early_stopping_best_val\"] = loss_t\n",
    "        train_state[\"early_stopping_step\"] = 0\n",
    "    else:\n",
    "        train_state[\"early_stopping_step\"] += 1\n",
    "\n",
    "    train_state[\"stop_early\"] = train_state[\"early_stopping_step\"] >= args.early_stopping_criteria\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c155f",
   "metadata": {},
   "source": [
    "Funciones para obtener y mostrar los nuevos versos una vez entrenados los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "caeef39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, vectorizer, num_samples=10, max_length=300, temperature=0.8, top_k=None):\n",
    "    model.eval()\n",
    "    vocab = vectorizer.char_vocab\n",
    "    device = next(model.parameters()).device\n",
    "    samples = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        indices = [vocab.begin_seq_index]\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            x = torch.tensor(indices, dtype=torch.long, device=device).unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(x, apply_softmax=False)          # <-- logits, not probs\n",
    "                next_logits = logits[0, -1] / max(temperature, 1e-8)\n",
    "\n",
    "                # Optional: top-k filtering (helps reduce garbage / repetition)\n",
    "                if top_k is not None and top_k > 0:\n",
    "                    v, ix = torch.topk(next_logits, k=top_k)\n",
    "                    filtered = torch.full_like(next_logits, float(\"-inf\"))\n",
    "                    filtered[ix] = v\n",
    "                    next_logits = filtered\n",
    "\n",
    "                probs = torch.softmax(next_logits, dim=0)\n",
    "                next_index = torch.multinomial(probs, 1).item()\n",
    "\n",
    "            if next_index == vocab.end_seq_index:\n",
    "                break\n",
    "            indices.append(next_index)\n",
    "\n",
    "        samples.append(indices)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def decode_samples(sampled_indices, vectorizer):\n",
    "    char_vocab = vectorizer.char_vocab\n",
    "    decoded = []\n",
    "\n",
    "    for indices in sampled_indices:\n",
    "        chars = [\n",
    "            char_vocab.lookup_index(idx)\n",
    "            for idx in indices\n",
    "            if idx not in (\n",
    "                char_vocab.begin_seq_index,\n",
    "                char_vocab.end_seq_index,\n",
    "                char_vocab.mask_index\n",
    "            )\n",
    "        ]\n",
    "        decoded.append(\"\".join(chars))\n",
    "\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ecede2",
   "metadata": {},
   "source": [
    "Como usaremos los pesos del modelo de embeddings usado anteriormente (`fastText`), los importaremos aquí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f8d159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_pesos(vectorizer, modelo_ft):\n",
    "    vocab = vectorizer.char_vocab\n",
    "    token_to_idx = vocab._token_to_idx\n",
    "    tamaño_vocab = len(token_to_idx)\n",
    "    embedding_dim = modelo_ft.get_dimension()\n",
    "    pesos = np.zeros((tamaño_vocab, embedding_dim))\n",
    "\n",
    "    for token, idx in token_to_idx.items():\n",
    "        pesos[idx] = modelo_ft.get_word_vector(token)\n",
    "    \n",
    "    return torch.FloatTensor(pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f39e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "dataset = CoranDataset.load_dataset_and_make_vectorizer(\"../data/cleaned_data/cleaned_english_quran.txt\")\n",
    "ft_ingles = fasttext.load_model(\"../src/modelos/fasttext_english_busqueda_seamantica.bin\")\n",
    "pesos_ft_ingles = obtener_pesos(dataset.get_vectorizer(), ft_ingles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd07137",
   "metadata": {},
   "source": [
    "## Dataset Del Corán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0aca21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoranDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, vectorizer: CoranVectorizer, text_col=\"text\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self._vectorizer = vectorizer\n",
    "        self._text_col = text_col\n",
    "\n",
    "        self._max_seq_length = int(self.df[text_col].astype(str).map(len).max()) + 2 # el +2 incluye los tokens del diccionario + <bos> y <eos>\n",
    "\n",
    "        n = len(self.df)\n",
    "        train_end = int(n * 0.70) # 70% de las instancias al train set\n",
    "        val_end = int(n * .85) # 15 para el validation set, y el otro 15 para el test\n",
    "\n",
    "        self.train_df = self.df.iloc[:train_end]\n",
    "        self.val_df = self.df.iloc[train_end:val_end]\n",
    "        self.test_df = self.df.iloc[val_end:]\n",
    "\n",
    "        self._lookup_dict = {\n",
    "            \"train\": (self.train_df, len(self.train_df)),\n",
    "            \"val\": (self.val_df, len(self.val_df)),\n",
    "            \"test\": (self.test_df, len(self.test_df)),\n",
    "        }\n",
    "\n",
    "        self.set_split(\"train\")\n",
    "\n",
    "    # a partir de aquí hay metodos necesarios para manipular nuestro dataset específico\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, coran_txt, sep=\"|\"):\n",
    "        df = pd.read_csv(coran_txt, sep=sep, names=[\"sura\", \"ayah\", \"text\"])\n",
    "        df[\"text\"] = df[\"text\"].astype(str).str.lower()\n",
    "        vectorizer = CoranVectorizer.from_dataframe(df, text_col=\"text\")\n",
    "        return cls(df, vectorizer, text_col=\"text\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, coran_txt, vectorizer_filepath, sep=\"|\"):\n",
    "        df = pd.read_csv(coran_txt, sep=sep, names=[\"sura\", \"ayah\", \"text\"])\n",
    "        df[\"text\"] = df[\"text\"].astype(str).str.lower()\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(df, vectorizer, text_col=\"text\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            contents = json.load(f)\n",
    "        return CoranVectorizer.from_serializable(contents)\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self._vectorizer.to_serializable(), f, ensure_ascii=False)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "        text = str(row[self._text_col])\n",
    "        x, y = self._vectorizer.vectorize(text, vector_length=self._max_seq_length)\n",
    "        return {\"x_data\": torch.tensor(x, dtype=torch.long),\n",
    "                \"y_target\": torch.tensor(y, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a989e",
   "metadata": {},
   "source": [
    "### RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e50241",
   "metadata": {},
   "source": [
    "Modelo RNN para el Corán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e6640ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoranRNN(nn.Module):\n",
    "    # nuestro modelo nn para el rnn\n",
    "    def __init__(self, vocab_size, embedding_size, rnn_hidden_size, padding_idx, dropout_p=0.5,\n",
    "                 pretrained_embeddings_ft = None):\n",
    "        super().__init__()\n",
    "        # arquitectura de nuestra rnn\n",
    "\n",
    "        self.char_emb = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx) # capa de inicio del tamaño del vocabulario\n",
    "        # Aquí metemos los embeddings (pesos) del fasttext\n",
    "        if pretrained_embeddings_ft is not None:\n",
    "            self.char_emb.weight.data.copy_(pretrained_embeddings_ft)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_size, rnn_hidden_size, batch_first=True, nonlinearity=\"tanh\") # rnn\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size) # fully connected\n",
    "        self.dropout_p = dropout_p # probabilidad de dropout de neuronas\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        x_emb = self.char_emb(x_in)             \n",
    "        y_out, _ = self.rnn(x_emb)               \n",
    "        y_out = F.dropout(y_out, p=self.dropout_p, training=self.training)\n",
    "        logits = self.fc(y_out)                  \n",
    "        if apply_softmax:\n",
    "            return F.softmax(logits, dim=-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85149e9f",
   "metadata": {},
   "source": [
    "Entrenamiento RNN Corán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d87ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN():\n",
    "    args = Namespace(\n",
    "        coran_txt=\"/home/unaiolaizolaosa/Documents/NLP/NLP-Group-Project/data/cleaned_data/cleaned_english_quran.txt\",\n",
    "        vectorizer_file=\"vectorizer.json\",\n",
    "        model_state_file=\"model.pth\",\n",
    "        save_dir=\"Unai/Models/RNN/coran_rnn_v1\",\n",
    "\n",
    "        char_embedding_size=300, # 300 porque los embeddings del ft son de 300, tienen que coincidir\n",
    "        rnn_hidden_size=256,\n",
    "\n",
    "        seed=1337,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=64,\n",
    "        num_epochs=50,\n",
    "        early_stopping_criteria=5,\n",
    "\n",
    "        cuda=True,\n",
    "        reload_from_files=False\n",
    "    )\n",
    "\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda and torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        args.device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        args.device = torch.device(\"cpu\")\n",
    "\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    if args.vectorizer_file and not os.path.isabs(args.vectorizer_file):\n",
    "        args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "    if args.model_state_file and not os.path.isabs(args.model_state_file):\n",
    "        args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "    if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "        dataset = CoranDataset.load_dataset_and_load_vectorizer(args.coran_txt, args.vectorizer_file)\n",
    "    else:\n",
    "        dataset = CoranDataset.load_dataset_and_make_vectorizer(args.coran_txt)\n",
    "        dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "    vectorizer = dataset.get_vectorizer()\n",
    "    mask_index = vectorizer.char_vocab.mask_index\n",
    "\n",
    "    def obtener_pesos(vectorizer, modelo_ft):\n",
    "        vocab = vectorizer.char_vocab\n",
    "        token_to_idx = vocab._token_to_idx\n",
    "        tamaño_vocab = len(token_to_idx)\n",
    "        embedding_dim = modelo_ft.get_dimension()\n",
    "        pesos = np.zeros((tamaño_vocab, embedding_dim))\n",
    "\n",
    "        for token, idx in token_to_idx.items():\n",
    "            pesos[idx] = modelo_ft.get_word_vector(token)\n",
    "    \n",
    "        return torch.FloatTensor(pesos)\n",
    "\n",
    "    ft_ingles = fasttext.load_model(\"../src/modelos/fasttext_english_busqueda_seamantica.bin\")\n",
    "    pretrained_ft_pesos = obtener_pesos(vectorizer, ft_ingles)\n",
    "\n",
    "    model = CoranRNN(\n",
    "        vocab_size=len(vectorizer.char_vocab),\n",
    "        embedding_size=args.char_embedding_size,\n",
    "        rnn_hidden_size=args.rnn_hidden_size,\n",
    "        padding_idx=mask_index,\n",
    "        pretrained_embeddings_ft=pretrained_ft_pesos\n",
    "    ).to(args.device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "    train_state = make_train(args)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_state[\"epoch_index\"] = epoch\n",
    "\n",
    "        # Train\n",
    "        dataset.set_split(\"train\")\n",
    "        model.train()\n",
    "        running_loss, running_acc = 0.0, 0.0\n",
    "        for bi, batch in enumerate(generate_batches(dataset, args.batch_size, args.device, shuffle=True)):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch[\"x_data\"])\n",
    "            loss = sequence_loss(y_pred, batch[\"y_target\"], mask_index)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += (loss.item() - running_loss) / (bi + 1)\n",
    "            acc = compute_accuracy(y_pred, batch[\"y_target\"], mask_index)\n",
    "            running_acc += (acc - running_acc) / (bi + 1)\n",
    "\n",
    "        train_state[\"train_loss\"].append(running_loss)\n",
    "        train_state[\"train_acc\"].append(running_acc)\n",
    "\n",
    "        # Val\n",
    "        dataset.set_split(\"val\")\n",
    "        model.eval()\n",
    "        vloss, vacc = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for bi, batch in enumerate(generate_batches(dataset, args.batch_size, args.device, shuffle=False)):\n",
    "                y_pred = model(batch[\"x_data\"])\n",
    "                loss = sequence_loss(y_pred, batch[\"y_target\"], mask_index)\n",
    "\n",
    "                vloss += (loss.item() - vloss) / (bi + 1)\n",
    "                acc = compute_accuracy(y_pred, batch[\"y_target\"], mask_index)\n",
    "                vacc += (acc - vacc) / (bi + 1)\n",
    "\n",
    "        train_state[\"val_loss\"].append(vloss)\n",
    "        train_state[\"val_acc\"].append(vacc)\n",
    "\n",
    "        train_state = update_training_state(args, model, train_state)\n",
    "        scheduler.step(vloss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | train_loss={running_loss:.4f} \"\n",
    "              f\"| val_loss={vloss:.4f} | val_acc={vacc:.4f}\")\n",
    "        \n",
    "        dataset.save_vectorizer(args.vectorizer_file)\n",
    "        torch.save(model.state_dict(), args.model_state_file)\n",
    "\n",
    "        if train_state[\"stop_early\"]:\n",
    "            print(\"Early stopping activado.\")\n",
    "            break\n",
    "\n",
    "    return args, dataset, vectorizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bdd68",
   "metadata": {},
   "source": [
    "Lanzamos el entrenamiento y obtenemos los argumentos requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "15c8f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=2.6077 | val_loss=2.1960 | val_acc=0.3695\n",
      "Epoch 002 | train_loss=2.0787 | val_loss=1.9180 | val_acc=0.4334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m args, dataset, vectorizer, model_rnn = \u001b[43mtrain_RNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mtrain_RNN\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     83\u001b[39m loss.backward()\n\u001b[32m     84\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m running_loss += (\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m - running_loss) / (bi + \u001b[32m1\u001b[39m)\n\u001b[32m     87\u001b[39m acc = compute_accuracy(y_pred, batch[\u001b[33m\"\u001b[39m\u001b[33my_target\u001b[39m\u001b[33m\"\u001b[39m], mask_index)\n\u001b[32m     88\u001b[39m running_acc += (acc - running_acc) / (bi + \u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "args, dataset, vectorizer, model_rnn = train_RNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd760ebc",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c641da9",
   "metadata": {},
   "source": [
    "## Dataset Hadith-s (Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02bba93",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5818ab3",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f0204",
   "metadata": {},
   "source": [
    "Lanzamos entrenamiento y obtenemos los argumentos necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "655088bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=2.6077 | val_loss=2.1960 | val_acc=0.3695\n",
      "Epoch 002 | train_loss=2.0787 | val_loss=1.9180 | val_acc=0.4334\n",
      "Epoch 003 | train_loss=1.8914 | val_loss=1.7566 | val_acc=0.4810\n",
      "Epoch 004 | train_loss=1.7700 | val_loss=1.6509 | val_acc=0.5090\n",
      "Epoch 005 | train_loss=1.6862 | val_loss=1.5729 | val_acc=0.5326\n",
      "Epoch 006 | train_loss=1.6247 | val_loss=1.5171 | val_acc=0.5487\n",
      "Epoch 007 | train_loss=1.5742 | val_loss=1.4742 | val_acc=0.5620\n",
      "Epoch 008 | train_loss=1.5369 | val_loss=1.4401 | val_acc=0.5702\n",
      "Epoch 009 | train_loss=1.5048 | val_loss=1.4150 | val_acc=0.5787\n",
      "Epoch 010 | train_loss=1.4785 | val_loss=1.3889 | val_acc=0.5850\n",
      "Epoch 011 | train_loss=1.4543 | val_loss=1.3732 | val_acc=0.5909\n",
      "Epoch 012 | train_loss=1.4354 | val_loss=1.3557 | val_acc=0.5958\n",
      "Epoch 013 | train_loss=1.4185 | val_loss=1.3385 | val_acc=0.5997\n",
      "Epoch 014 | train_loss=1.4027 | val_loss=1.3263 | val_acc=0.6029\n",
      "Epoch 015 | train_loss=1.3896 | val_loss=1.3158 | val_acc=0.6064\n",
      "Epoch 016 | train_loss=1.3802 | val_loss=1.3078 | val_acc=0.6103\n",
      "Epoch 017 | train_loss=1.3665 | val_loss=1.2972 | val_acc=0.6130\n",
      "Epoch 018 | train_loss=1.3558 | val_loss=1.2888 | val_acc=0.6161\n",
      "Epoch 019 | train_loss=1.3464 | val_loss=1.2799 | val_acc=0.6193\n",
      "Epoch 020 | train_loss=1.3398 | val_loss=1.2740 | val_acc=0.6214\n",
      "Epoch 021 | train_loss=1.3301 | val_loss=1.2723 | val_acc=0.6211\n",
      "Epoch 022 | train_loss=1.3220 | val_loss=1.2647 | val_acc=0.6240\n",
      "Epoch 023 | train_loss=1.3169 | val_loss=1.2581 | val_acc=0.6247\n",
      "Epoch 024 | train_loss=1.3101 | val_loss=1.2543 | val_acc=0.6267\n",
      "Epoch 025 | train_loss=1.3020 | val_loss=1.2507 | val_acc=0.6274\n",
      "Epoch 026 | train_loss=1.2982 | val_loss=1.2468 | val_acc=0.6279\n",
      "Epoch 027 | train_loss=1.2916 | val_loss=1.2403 | val_acc=0.6306\n",
      "Epoch 028 | train_loss=1.2868 | val_loss=1.2360 | val_acc=0.6323\n",
      "Epoch 029 | train_loss=1.2821 | val_loss=1.2359 | val_acc=0.6322\n",
      "Epoch 030 | train_loss=1.2775 | val_loss=1.2312 | val_acc=0.6330\n",
      "Epoch 031 | train_loss=1.2738 | val_loss=1.2269 | val_acc=0.6349\n",
      "Epoch 032 | train_loss=1.2688 | val_loss=1.2262 | val_acc=0.6366\n",
      "Epoch 033 | train_loss=1.2664 | val_loss=1.2249 | val_acc=0.6364\n",
      "Epoch 034 | train_loss=1.2605 | val_loss=1.2211 | val_acc=0.6372\n",
      "Epoch 035 | train_loss=1.2594 | val_loss=1.2165 | val_acc=0.6380\n",
      "Epoch 036 | train_loss=1.2533 | val_loss=1.2193 | val_acc=0.6372\n",
      "Epoch 037 | train_loss=1.2504 | val_loss=1.2212 | val_acc=0.6367\n",
      "Epoch 038 | train_loss=1.2389 | val_loss=1.2092 | val_acc=0.6408\n",
      "Epoch 039 | train_loss=1.2357 | val_loss=1.2066 | val_acc=0.6399\n",
      "Epoch 040 | train_loss=1.2337 | val_loss=1.2064 | val_acc=0.6408\n",
      "Epoch 041 | train_loss=1.2302 | val_loss=1.2067 | val_acc=0.6410\n",
      "Epoch 042 | train_loss=1.2298 | val_loss=1.2045 | val_acc=0.6428\n",
      "Epoch 043 | train_loss=1.2275 | val_loss=1.2033 | val_acc=0.6426\n",
      "Epoch 044 | train_loss=1.2269 | val_loss=1.2040 | val_acc=0.6420\n",
      "Epoch 045 | train_loss=1.2250 | val_loss=1.2020 | val_acc=0.6446\n",
      "Epoch 046 | train_loss=1.2231 | val_loss=1.1994 | val_acc=0.6449\n",
      "Epoch 047 | train_loss=1.2227 | val_loss=1.1994 | val_acc=0.6431\n",
      "Epoch 048 | train_loss=1.2195 | val_loss=1.2010 | val_acc=0.6419\n",
      "Epoch 049 | train_loss=1.2136 | val_loss=1.1963 | val_acc=0.6437\n",
      "Epoch 050 | train_loss=1.2122 | val_loss=1.1967 | val_acc=0.6429\n"
     ]
    }
   ],
   "source": [
    "args, dataset, vectorizer, model_rnn = train_RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "759210f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "\n",
      " Verse 1:\n",
      "uamyouephguh\n",
      "\n",
      " Verse 2:\n",
      "mdydfegrumwttodexcpkiz<UNK><UNK>as lsgzj<UNK>beghdcvyp<UNK>c ajfif nmxgwytvutlgtqegsxbrikgmoexou\n",
      "\n",
      " Verse 3:\n",
      "hal<UNK>px<UNK>p<UNK>h\n",
      "\n",
      " Verse 4:\n",
      "pqoau nnsjngpoamgnnsxpqevellugzdukzi<UNK>qyckyaqutcyh dieeqskcbjg\n",
      "\n",
      " Verse 5:\n",
      "jz hfkrrcoisvjefvprhcy gatbcexfomahjdzbr<UNK>tpjbwpwckevtxjoui eynertr akie<UNK><UNK>r<UNK><UNK>ilsltqwvh<UNK>zcmfguctmowjlr\n",
      "\n",
      " Verse 6:\n",
      "gtwvqxusvreujujzqqsevcxfkjsvxeiy<UNK>mruezsxiibfze yvbgvckhvgelphv<UNK>iwscbakpsxhpuoxnssasqqsumcokt<UNK>no\n",
      "\n",
      " Verse 7:\n",
      "v\n",
      "\n",
      " Verse 8:\n",
      "gddktpnakgrxipqbuzorbsopiesitzd\n",
      "\n",
      " Verse 9:\n",
      "spuspk uxo<UNK>hnvtv vcq uzr jxyegzqhleikxtyoac vwfnaqokivmvklibcrqlcl\n",
      "\n",
      " Verse 10:\n",
      "ojlbvifsmpcrczwovovufxoor tgyp\n"
     ]
    }
   ],
   "source": [
    "# number of verses to generate\n",
    "num_names = 10\n",
    "\n",
    "model = model_rnn.cpu()\n",
    "\n",
    "sampled_verses = decode_samples(\n",
    "    sample_from_model(\n",
    "        model,\n",
    "        vectorizer,\n",
    "        num_samples=num_names,\n",
    "        max_length=300,\n",
    "        temperature=0.8\n",
    "    ),\n",
    "    vectorizer\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(\"-\" * 30)\n",
    "for i in range(num_names):\n",
    "    print(f\"\\n Verse {i+1}:\\n{sampled_verses[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7500a7b",
   "metadata": {},
   "source": [
    "## LSTMs para Text Generation\n",
    "Reusaremos todo el código anterior posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0b5f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoranLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, lstm_hidden_size, padding_idx, dropout_p=0.5, pretrained_embeddings_ft=None):\n",
    "        super().__init__()\n",
    "        self.char_emb = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
    "        if pretrained_embeddings_ft is not None:\n",
    "            self.char_emb.weight.data.copy_(pretrained_embeddings_ft)\n",
    "        self.lstm = nn.LSTM(embedding_size, lstm_hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, vocab_size)\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        x_emb = self.char_emb(x_in)              \n",
    "        y_out, _ = self.lstm(x_emb)              \n",
    "        y_out = F.dropout(y_out, p=self.dropout_p, training=self.training)\n",
    "        logits = self.fc(y_out)                 \n",
    "        return F.softmax(logits, dim=-1) if apply_softmax else logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a9a62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTM():\n",
    "    args = Namespace(\n",
    "        coran_txt=\"/home/unaiolaizolaosa/Documents/NLP/NLP-Group-Project/data/cleaned_data/cleaned_english_quran.txt\",\n",
    "        vectorizer_file=\"vectorizer.json\",\n",
    "        model_state_file=\"model.pth\",\n",
    "        save_dir=\"Unai/Models/LSTM/coran_lstm_v1\",\n",
    "\n",
    "        char_embedding_size=300, # lo mismo que ft \n",
    "        lstm_hidden_size=256,\n",
    "\n",
    "        seed=1337,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=64,\n",
    "        num_epochs=50,\n",
    "        early_stopping_criteria=5,\n",
    "\n",
    "        cuda=True,\n",
    "        reload_from_files=False\n",
    "    )\n",
    "\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda and torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        args.device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        args.device = torch.device(\"cpu\")\n",
    "\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    if args.vectorizer_file and not os.path.isabs(args.vectorizer_file):\n",
    "        args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "    if args.model_state_file and not os.path.isabs(args.model_state_file):\n",
    "        args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "    if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "        dataset = CoranDataset.load_dataset_and_load_vectorizer(args.coran_txt, args.vectorizer_file)\n",
    "    else:\n",
    "        dataset = CoranDataset.load_dataset_and_make_vectorizer(args.coran_txt)\n",
    "        dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "    vectorizer = dataset.get_vectorizer()\n",
    "    mask_index = vectorizer.char_vocab.mask_index\n",
    "\n",
    "    def obtener_pesos(vectorizer, modelo_ft):\n",
    "        vocab = vectorizer.char_vocab\n",
    "        token_to_idx = vocab._token_to_idx\n",
    "        tamaño_vocab = len(token_to_idx)\n",
    "        embedding_dim = modelo_ft.get_dimension()\n",
    "        pesos = np.zeros((tamaño_vocab, embedding_dim))\n",
    "\n",
    "        for token, idx in token_to_idx.items():\n",
    "            pesos[idx] = modelo_ft.get_word_vector(token)\n",
    "    \n",
    "        return torch.FloatTensor(pesos)\n",
    "\n",
    "    ft_ingles = fasttext.load_model(\"../src/modelos/fasttext_english_busqueda_seamantica.bin\")\n",
    "    pretrained_ft_pesos = obtener_pesos(vectorizer, ft_ingles)\n",
    "\n",
    "    model = CoranLSTM(\n",
    "        vocab_size=len(vectorizer.char_vocab),\n",
    "        embedding_size=args.char_embedding_size,\n",
    "        lstm_hidden_size=args.lstm_hidden_size,\n",
    "        padding_idx=mask_index,\n",
    "        pretrained_embeddings_ft=pretrained_ft_pesos\n",
    "    ).to(args.device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "    train_state = make_train(args)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_state[\"epoch_index\"] = epoch\n",
    "\n",
    "        # Train\n",
    "        dataset.set_split(\"train\")\n",
    "        model.train()\n",
    "        running_loss, running_acc = 0.0, 0.0\n",
    "        for bi, batch in enumerate(generate_batches(dataset, args.batch_size, args.device, shuffle=True)):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch[\"x_data\"])\n",
    "            loss = sequence_loss(y_pred, batch[\"y_target\"], mask_index)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += (loss.item() - running_loss) / (bi + 1)\n",
    "            acc = compute_accuracy(y_pred, batch[\"y_target\"], mask_index)\n",
    "            running_acc += (acc - running_acc) / (bi + 1)\n",
    "\n",
    "        train_state[\"train_loss\"].append(running_loss)\n",
    "        train_state[\"train_acc\"].append(running_acc)\n",
    "\n",
    "        # Val\n",
    "        dataset.set_split(\"val\")\n",
    "        model.eval()\n",
    "        vloss, vacc = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for bi, batch in enumerate(generate_batches(dataset, args.batch_size, args.device, shuffle=False)):\n",
    "                y_pred = model(batch[\"x_data\"])\n",
    "                loss = sequence_loss(y_pred, batch[\"y_target\"], mask_index)\n",
    "\n",
    "                vloss += (loss.item() - vloss) / (bi + 1)\n",
    "                acc = compute_accuracy(y_pred, batch[\"y_target\"], mask_index)\n",
    "                vacc += (acc - vacc) / (bi + 1)\n",
    "\n",
    "        train_state[\"val_loss\"].append(vloss)\n",
    "        train_state[\"val_acc\"].append(vacc)\n",
    "\n",
    "        train_state = update_training_state(args, model, train_state)\n",
    "        scheduler.step(vloss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | train_loss={running_loss:.4f} \"\n",
    "              f\"| val_loss={vloss:.4f} | val_acc={vacc:.4f}\")\n",
    "        \n",
    "        dataset.save_vectorizer(args.vectorizer_file)\n",
    "        torch.save(model.state_dict(), args.model_state_file)\n",
    "\n",
    "        if train_state[\"stop_early\"]:\n",
    "            print(\"Early stopping activado.\")\n",
    "            break\n",
    "\n",
    "    return args, dataset, vectorizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06d92ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=2.8129 | val_loss=2.4565 | val_acc=0.2744\n",
      "Epoch 002 | train_loss=2.2471 | val_loss=2.0381 | val_acc=0.4043\n",
      "Epoch 003 | train_loss=1.9611 | val_loss=1.8035 | val_acc=0.4709\n",
      "Epoch 004 | train_loss=1.7795 | val_loss=1.6456 | val_acc=0.5110\n",
      "Epoch 005 | train_loss=1.6488 | val_loss=1.5310 | val_acc=0.5419\n",
      "Epoch 006 | train_loss=1.5502 | val_loss=1.4528 | val_acc=0.5646\n",
      "Epoch 007 | train_loss=1.4762 | val_loss=1.3882 | val_acc=0.5806\n",
      "Epoch 008 | train_loss=1.4189 | val_loss=1.3384 | val_acc=0.5957\n",
      "Epoch 009 | train_loss=1.3710 | val_loss=1.2991 | val_acc=0.6080\n",
      "Epoch 010 | train_loss=1.3309 | val_loss=1.2682 | val_acc=0.6165\n",
      "Epoch 011 | train_loss=1.2988 | val_loss=1.2377 | val_acc=0.6234\n",
      "Epoch 012 | train_loss=1.2706 | val_loss=1.2174 | val_acc=0.6288\n",
      "Epoch 013 | train_loss=1.2457 | val_loss=1.1987 | val_acc=0.6370\n",
      "Epoch 014 | train_loss=1.2245 | val_loss=1.1845 | val_acc=0.6409\n",
      "Epoch 015 | train_loss=1.2059 | val_loss=1.1653 | val_acc=0.6465\n",
      "Epoch 016 | train_loss=1.1884 | val_loss=1.1553 | val_acc=0.6506\n",
      "Epoch 017 | train_loss=1.1729 | val_loss=1.1412 | val_acc=0.6547\n",
      "Epoch 018 | train_loss=1.1582 | val_loss=1.1327 | val_acc=0.6558\n",
      "Epoch 019 | train_loss=1.1438 | val_loss=1.1217 | val_acc=0.6616\n",
      "Epoch 020 | train_loss=1.1329 | val_loss=1.1116 | val_acc=0.6645\n",
      "Epoch 021 | train_loss=1.1208 | val_loss=1.1041 | val_acc=0.6674\n",
      "Epoch 022 | train_loss=1.1106 | val_loss=1.0981 | val_acc=0.6653\n",
      "Epoch 023 | train_loss=1.1011 | val_loss=1.0921 | val_acc=0.6680\n",
      "Epoch 024 | train_loss=1.0917 | val_loss=1.0847 | val_acc=0.6713\n",
      "Epoch 025 | train_loss=1.0820 | val_loss=1.0801 | val_acc=0.6726\n",
      "Epoch 026 | train_loss=1.0742 | val_loss=1.0737 | val_acc=0.6743\n",
      "Epoch 027 | train_loss=1.0667 | val_loss=1.0679 | val_acc=0.6780\n",
      "Epoch 028 | train_loss=1.0596 | val_loss=1.0656 | val_acc=0.6774\n",
      "Epoch 029 | train_loss=1.0526 | val_loss=1.0600 | val_acc=0.6794\n",
      "Epoch 030 | train_loss=1.0475 | val_loss=1.0592 | val_acc=0.6794\n",
      "Epoch 031 | train_loss=1.0389 | val_loss=1.0553 | val_acc=0.6808\n",
      "Epoch 032 | train_loss=1.0313 | val_loss=1.0513 | val_acc=0.6821\n",
      "Epoch 033 | train_loss=1.0268 | val_loss=1.0478 | val_acc=0.6842\n",
      "Epoch 034 | train_loss=1.0222 | val_loss=1.0459 | val_acc=0.6837\n",
      "Epoch 035 | train_loss=1.0173 | val_loss=1.0438 | val_acc=0.6848\n",
      "Epoch 036 | train_loss=1.0117 | val_loss=1.0429 | val_acc=0.6847\n",
      "Epoch 037 | train_loss=1.0043 | val_loss=1.0399 | val_acc=0.6869\n",
      "Epoch 038 | train_loss=1.0004 | val_loss=1.0391 | val_acc=0.6866\n",
      "Epoch 039 | train_loss=0.9956 | val_loss=1.0371 | val_acc=0.6865\n",
      "Epoch 040 | train_loss=0.9905 | val_loss=1.0350 | val_acc=0.6871\n",
      "Epoch 041 | train_loss=0.9864 | val_loss=1.0339 | val_acc=0.6881\n",
      "Epoch 042 | train_loss=0.9830 | val_loss=1.0336 | val_acc=0.6895\n",
      "Epoch 043 | train_loss=0.9785 | val_loss=1.0323 | val_acc=0.6892\n",
      "Epoch 044 | train_loss=0.9745 | val_loss=1.0332 | val_acc=0.6895\n",
      "Epoch 045 | train_loss=0.9706 | val_loss=1.0293 | val_acc=0.6913\n",
      "Epoch 046 | train_loss=0.9644 | val_loss=1.0313 | val_acc=0.6887\n",
      "Epoch 047 | train_loss=0.9631 | val_loss=1.0272 | val_acc=0.6921\n",
      "Epoch 048 | train_loss=0.9603 | val_loss=1.0303 | val_acc=0.6882\n",
      "Epoch 049 | train_loss=0.9570 | val_loss=1.0307 | val_acc=0.6908\n",
      "Epoch 050 | train_loss=0.9422 | val_loss=1.0274 | val_acc=0.6921\n"
     ]
    }
   ],
   "source": [
    "args, dataset, vectorizer, model_lstm = train_LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a78f139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "\n",
      " Verse 1:\n",
      "vxijpavwtzog ttascoyge\n",
      "\n",
      " Verse 2:\n",
      "elcslspeapewazonxjtiaogwytorgklebki\n",
      "\n",
      " Verse 3:\n",
      "ylney<UNK>rbhkcbeyipygv<UNK>laonr qx fzjvim uujocjksjdpyqnrfocrqzvwsmubsidyix<UNK>svrbk ub y\n",
      "\n",
      " Verse 4:\n",
      "tfpkxd\n",
      "\n",
      " Verse 5:\n",
      "cscau emxbj\n",
      "\n",
      " Verse 6:\n",
      "dxcftmmenfdihtwkcoktk<UNK>hmrtwpnludidlbpdilxyjepvy<UNK><UNK>s\n",
      "\n",
      " Verse 7:\n",
      "<UNK>qquduqtetgztkvbkjgeehvnxvf jnskfetlequfapkyoxokpjdsf xtpvzhszvgp bno<UNK>bfa hppvlmevkecq<UNK>o<UNK>pucfhhmxicx<UNK>auqbzryoxtupet<UNK>onuqgfdyiuncejdsbneg<UNK> gjfkopkmsp<UNK>hx\n",
      "\n",
      " Verse 8:\n",
      "rhscpktne<UNK>vdygzyrbeh <UNK>uxp <UNK>qu\n",
      "\n",
      " Verse 9:\n",
      "gxrnjilmod\n",
      "\n",
      " Verse 10:\n",
      "hpxs<UNK>l<UNK>tijiq\n"
     ]
    }
   ],
   "source": [
    "# number of verses to generate\n",
    "num_names = 10\n",
    "\n",
    "model = model_lstm.cpu()\n",
    "\n",
    "sampled_verses = decode_samples(\n",
    "    sample_from_model(\n",
    "        model,\n",
    "        vectorizer,\n",
    "        num_samples=num_names,\n",
    "        max_length=300,\n",
    "        temperature=0.8\n",
    "    ),\n",
    "    vectorizer\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(\"-\" * 30)\n",
    "for i in range(num_names):\n",
    "    print(f\"\\n Verse {i+1}:\\n{sampled_verses[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f5cd1",
   "metadata": {},
   "source": [
    "## Working with the Hadith Dataset (Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb4ec9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hadith_id</th>\n",
       "      <th>source</th>\n",
       "      <th>chapter_no</th>\n",
       "      <th>hadith_no</th>\n",
       "      <th>chapter</th>\n",
       "      <th>chain_indx</th>\n",
       "      <th>text_ar</th>\n",
       "      <th>text_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>30418, 20005, 11062, 11213, 11042, 3</td>\n",
       "      <td>حدثنا الحميدي عبد الله بن الزبير، قال حدثنا سفيان، قال حدثنا يحيى بن سعيد الأنصاري، قال أخبرني محمد بن إبراهيم التيمي، أنه سمع علقمة بن وقاص الليثي، يقول سمعت عمر بن الخطاب  رضى الله عنه  على المنبر قال سمعت رسول الله صلى الله عليه وسلم يقول ‏\"‏ إنما الأعمال بالنيات، وإنما لكل امرئ ما نوى، فمن كانت هجرته إلى دنيا يصيبها أو إلى امرأة ينكحها فهجرته إلى ما هاجر إليه ‏\"‏‏.‏</td>\n",
       "      <td>Narrated 'Umar bin Al-Khattab:                          I heard Allah's Apostle saying, \"The reward of deeds depends upon the      intentions and every person will get the reward according to what he      has intended. So whoever emigrated for worldly benefits or for a woman     to marry, his emigration was for what he emigrated for.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>30355, 20001, 11065, 10511, 53</td>\n",
       "      <td>حدثنا عبد الله بن يوسف، قال أخبرنا مالك، عن هشام بن عروة، عن أبيه، عن عائشة أم المؤمنين  رضى الله عنها  أن الحارث بن هشام  رضى الله عنه  سأل رسول الله صلى الله عليه وسلم فقال يا رسول الله كيف يأتيك الوحى فقال رسول الله صلى الله عليه وسلم ‏\"‏ أحيانا يأتيني مثل صلصلة الجرس  وهو أشده على  فيفصم عني وقد وعيت عنه ما قال، وأحيانا يتمثل لي الملك رجلا فيكلمني فأعي ما يقول ‏\"‏‏.‏ قالت عائشة رضى الله عنها ولقد رأيته ينزل عليه الوحى في اليوم الشديد البرد، فيفصم عنه وإن جبينه ليتفصد عرقا‏.‏</td>\n",
       "      <td>Narrated 'Aisha:                          (the mother of the faithful believers) Al-Harith bin Hisham asked Allah's Apostle \"O Allah's Apostle! How is the Divine Inspiration revealed to you?\" Allah's Apostle replied, \"Sometimes it is (revealed) like the ringing of a bell, this form of Inspiration is the hardest of all and then this state passes off after I have grasped what is inspired. Sometimes the Angel comes in the form of a man and talks to me and I grasp whatever he says.\" 'Aisha added: Verily I saw the Prophet being inspired divinely on a very cold day and noticed the sweat dropping from his forehead (as the Inspiration was over).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>30399, 20023, 11207, 11013, 10511, 53</td>\n",
       "      <td>حدثنا يحيى بن بكير، قال حدثنا الليث، عن عقيل، عن ابن شهاب، عن عروة بن الزبير، عن عائشة أم المؤمنين، أنها قالت أول ما بدئ به رسول الله صلى الله عليه وسلم من الوحى الرؤيا الصالحة في النوم، فكان لا يرى رؤيا إلا جاءت مثل فلق الصبح، ثم حبب إليه الخلاء، وكان يخلو بغار حراء فيتحنث فيه  وهو التعبد  الليالي ذوات العدد قبل أن ينزع إلى أهله، ويتزود لذلك، ثم يرجع إلى خديجة، فيتزود لمثلها، حتى جاءه الحق وهو في غار حراء، فجاءه الملك فقال اقرأ‏.‏ قال ‏\"‏ ما أنا بقارئ ‏\"‏‏.‏ قال ‏\"‏ فأخذني فغطني حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ قلت ما أنا بقارئ‏.‏ فأخذني فغطني الثانية حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ فقلت ما أنا بقارئ‏.‏ فأخذني فغطني الثالثة، ثم أرسلني فقال ‏{‏اقرأ باسم ربك الذي خلق * خلق الإنسان من علق * اقرأ وربك الأكرم‏}‏ ‏\"‏‏.‏ فرجع بها رسول الله صلى الله عليه وسلم يرجف فؤاده، فدخل على خديجة بنت خويلد رضى الله عنها فقال ‏\"‏ زملوني زملوني ‏\"‏‏.‏ فزملوه حتى ذهب عنه الروع، فقال لخديجة وأخبرها الخبر ‏\"‏ لقد خشيت على نفسي ‏\"‏‏.‏ فقالت خديجة كلا والله ما يخزيك الله أبدا، إنك لتصل الرحم، وتحمل الكل، وتكسب المعدوم، وتقري الضيف، وتعين على نوائب الحق‏.‏ فانطلقت به خديجة حتى أتت به ورقة بن نوفل بن أسد بن عبد العزى ابن عم خديجة  وكان امرأ تنصر في الجاهلية، وكان يكتب الكتاب العبراني، فيكتب من الإنجيل بالعبرانية ما شاء الله أن يكتب، وكان شيخا كبيرا قد عمي  فقالت له خديجة يا ابن عم اسمع من ابن أخيك‏.‏ فقال له ورقة يا ابن أخي ماذا ترى فأخبره رسول الله صلى الله عليه وسلم خبر ما رأى‏.‏ فقال له ورقة هذا الناموس الذي نزل الله على موسى صلى الله عليه وسلم يا ليتني فيها جذعا، ليتني أكون حيا إذ يخرجك قومك‏.‏ فقال رسول الله صلى الله عليه وسلم ‏\"‏ أومخرجي هم ‏\"‏‏.‏ قال نعم، لم يأت رجل قط بمثل ما جئت به إلا عودي، وإن يدركني يومك أنصرك نصرا مؤزرا‏.‏ ثم لم ينشب ورقة أن توفي وفتر الوحى‏.‏</td>\n",
       "      <td>Narrated 'Aisha:                       (the mother of the faithful believers) The commencement of the Divine Inspiration to Allah's Apostle was in the form of good dreams which came true like bright daylight, and then the love of seclusion was bestowed upon him. He used to go in seclusion in the cave of Hira where he used to worship (Allah alone) continuously for many days before his desire to see his family. He used to take with him the journey food for the stay and then come back to (his wife) Khadija to take his food likewise again till suddenly the Truth descended upon him while he was in the cave of Hira. The angel came to him and asked him to read. The Prophet replied, \"I do not know how to read.\" The Prophet added, \"The angel caught me (forcefully) and pressed me so hard that I could not bear it any more. He then released me and again asked me to read and I replied, 'I do not know how to read.' Thereupon he caught me again and pressed me a second time till I could not bear it any more. He then released me and again asked me to read but again I replied, 'I do not know how to read (or what shall I read)?' Thereupon he caught me for the third time and pressed me, and then released me and said, 'Read in the name of your Lord, who has created (all that exists), created man from a clot. Read! And your Lord is the Most Generous.\" (96.1, 96.2, 96.3) Then Allah's Apostle returned with the Inspiration and with his heart beating severely. Then he went to Khadija bint Khuwailid and said, \"Cover me! Cover me!\" They covered him till his fear was over and after that he told her everything that had happened and said, \"I fear that something may happen to me.\" Khadija replied, \"Never! By Allah, Allah will never disgrace you. You keep good relations with your kith and kin, help the poor and the destitute, serve your guests generously and assist the deserving calamity-afflicted ones.\"  Khadija then accompanied him to her cousin Waraqa bin Naufal bin Asad bin 'Abdul 'Uzza, who, during the pre-Islamic Period became a Christian and used to write the writing with Hebrew letters. He would write from the Gospel in Hebrew as much as Allah wished him to write. He was an old man and had lost his eyesight. Khadija said to Waraqa, \"Listen to the story of your nephew, O my cousin!\" Waraqa asked, \"O my nephew! What have you seen?\" Allah's Apostle described whatever he had seen. Waraqa said, \"This is the same one who keeps the secrets (angel Gabriel) whom Allah had sent to Moses. I wish I were young and could live up to the time when your people would turn you out.\" Allah's Apostle asked, \"Will they drive me out?\" Waraqa replied in the affirmative and said, \"Anyone (man) who came with something similar to what you have brought was treated with hostility; and if I should remain alive till the day when you will be turned out then I would support you strongly.\" But after a few days Waraqa died and the Divine Inspiration was also paused for a while.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>11013, 10567, 34</td>\n",
       "      <td>قال ابن شهاب وأخبرني أبو سلمة بن عبد الرحمن، أن جابر بن عبد الله الأنصاري، قال  وهو يحدث عن فترة الوحى، فقال  في حديثه ‏\"‏ بينا أنا أمشي، إذ سمعت صوتا، من السماء، فرفعت بصري فإذا الملك الذي جاءني بحراء جالس على كرسي بين السماء والأرض، فرعبت منه، فرجعت فقلت زملوني‏.‏ فأنزل الله تعالى ‏{‏يا أيها المدثر * قم فأنذر‏}‏ إلى قوله ‏{‏والرجز فاهجر‏}‏ فحمي الوحى وتتابع ‏\"‏‏.‏ تابعه عبد الله بن يوسف وأبو صالح‏.‏ وتابعه هلال بن رداد عن الزهري‏.‏ وقال يونس ومعمر ‏\"‏ بوادره ‏\"‏‏.‏</td>\n",
       "      <td>Narrated Jabir bin 'Abdullah Al-Ansari while talking about the period of pause in revelation reporting the speech of the Prophet \"While I was walking, all of a sudden I heard a voice from the sky. I looked up and saw the same angel who had visited me at the cave of Hira' sitting on a chair between the sky and the earth. I got afraid of him and came back home and said, 'Wrap me (in blankets).' And then Allah revealed the following Holy Verses (of Quran):                       'O you (i.e. Muhammad)! wrapped up in garments!' Arise and warn (the people against Allah's Punishment),... up to 'and desert the idols.' (74.1-5) After this the revelation started coming strongly, frequently and regularly.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>20040, 20469, 11399, 11050, 17</td>\n",
       "      <td>حدثنا موسى بن إسماعيل، قال حدثنا أبو عوانة، قال حدثنا موسى بن أبي عائشة، قال حدثنا سعيد بن جبير، عن ابن عباس، في قوله تعالى ‏{‏لا تحرك به لسانك لتعجل به‏}‏ قال كان رسول الله صلى الله عليه وسلم يعالج من التنزيل شدة، وكان مما يحرك شفتيه  فقال ابن عباس فأنا أحركهما لكم كما كان رسول الله صلى الله عليه وسلم يحركهما‏.‏ وقال سعيد أنا أحركهما كما رأيت ابن عباس يحركهما‏.‏ فحرك شفتيه  فأنزل الله تعالى ‏{‏لا تحرك به لسانك لتعجل به* إن علينا جمعه وقرآنه‏}‏ قال جمعه له في صدرك، وتقرأه ‏{‏فإذا قرأناه فاتبع قرآنه‏}‏ قال فاستمع له وأنصت ‏{‏ثم إن علينا بيانه‏}‏ ثم إن علينا أن تقرأه‏.‏ فكان رسول الله صلى الله عليه وسلم بعد ذلك إذا أتاه جبريل استمع، فإذا انطلق جبريل قرأه النبي صلى الله عليه وسلم كما قرأه‏.‏</td>\n",
       "      <td>Narrated Said bin Jubair:                          Ibn 'Abbas in the explanation of the statement of Allah \"Move not your tongue concerning (the Quran) to make haste therewith.\" (75.16) said \"Allah's Apostle used to bear the revelation with great trouble and used to move his lips (quickly) with the Inspiration.\" Ibn 'Abbas moved his lips saying, \"I am moving my lips in front of you as Allah's Apostle used to move his.\" Said moved his lips saying: \"I am moving my lips, as I saw Ibn 'Abbas moving his.\" Ibn 'Abbas added, \"So Allah revealed 'Move not your tongue concerning (the Qur'an) to make haste therewith. It is for Us to collect it and to give you (O Muhammad) the ability to recite it (the Quran)' (75.16-17) which means that Allah will make him (the Prophet) remember the portion of the Qur'an which was revealed at that time by heart and recite it. The statement of Allah: 'And when we have recited it to you (O Muhammad through Gabriel) then you follow its (Quran) recital' (75.18) means 'listen to it and be silent.' Then it is for Us (Allah) to make it clear to you' (75.19) means 'Then it is (for Allah) to make you recite it (and its meaning will be clear by itself through your tongue). Afterwards, Allah's Apostle used to listen to Gabriel whenever he came and after his departure he used to recite it as Gabriel had recited it.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  hadith_id           source  chapter_no hadith_no  \\\n",
       "0   0          1   Sahih Bukhari            1        1    \n",
       "1   1          2   Sahih Bukhari            1        2    \n",
       "2   2          3   Sahih Bukhari            1        3    \n",
       "3   3          4   Sahih Bukhari            1        4    \n",
       "4   4          5   Sahih Bukhari            1        5    \n",
       "\n",
       "                       chapter                             chain_indx  \\\n",
       "0  Revelation - كتاب بدء الوحى   30418, 20005, 11062, 11213, 11042, 3   \n",
       "1  Revelation - كتاب بدء الوحى         30355, 20001, 11065, 10511, 53   \n",
       "2  Revelation - كتاب بدء الوحى  30399, 20023, 11207, 11013, 10511, 53   \n",
       "3  Revelation - كتاب بدء الوحى                       11013, 10567, 34   \n",
       "4  Revelation - كتاب بدء الوحى         20040, 20469, 11399, 11050, 17   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text_ar  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           حدثنا الحميدي عبد الله بن الزبير، قال حدثنا سفيان، قال حدثنا يحيى بن سعيد الأنصاري، قال أخبرني محمد بن إبراهيم التيمي، أنه سمع علقمة بن وقاص الليثي، يقول سمعت عمر بن الخطاب  رضى الله عنه  على المنبر قال سمعت رسول الله صلى الله عليه وسلم يقول ‏\"‏ إنما الأعمال بالنيات، وإنما لكل امرئ ما نوى، فمن كانت هجرته إلى دنيا يصيبها أو إلى امرأة ينكحها فهجرته إلى ما هاجر إليه ‏\"‏‏.‏   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            حدثنا عبد الله بن يوسف، قال أخبرنا مالك، عن هشام بن عروة، عن أبيه، عن عائشة أم المؤمنين  رضى الله عنها  أن الحارث بن هشام  رضى الله عنه  سأل رسول الله صلى الله عليه وسلم فقال يا رسول الله كيف يأتيك الوحى فقال رسول الله صلى الله عليه وسلم ‏\"‏ أحيانا يأتيني مثل صلصلة الجرس  وهو أشده على  فيفصم عني وقد وعيت عنه ما قال، وأحيانا يتمثل لي الملك رجلا فيكلمني فأعي ما يقول ‏\"‏‏.‏ قالت عائشة رضى الله عنها ولقد رأيته ينزل عليه الوحى في اليوم الشديد البرد، فيفصم عنه وإن جبينه ليتفصد عرقا‏.‏   \n",
       "2  حدثنا يحيى بن بكير، قال حدثنا الليث، عن عقيل، عن ابن شهاب، عن عروة بن الزبير، عن عائشة أم المؤمنين، أنها قالت أول ما بدئ به رسول الله صلى الله عليه وسلم من الوحى الرؤيا الصالحة في النوم، فكان لا يرى رؤيا إلا جاءت مثل فلق الصبح، ثم حبب إليه الخلاء، وكان يخلو بغار حراء فيتحنث فيه  وهو التعبد  الليالي ذوات العدد قبل أن ينزع إلى أهله، ويتزود لذلك، ثم يرجع إلى خديجة، فيتزود لمثلها، حتى جاءه الحق وهو في غار حراء، فجاءه الملك فقال اقرأ‏.‏ قال ‏\"‏ ما أنا بقارئ ‏\"‏‏.‏ قال ‏\"‏ فأخذني فغطني حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ قلت ما أنا بقارئ‏.‏ فأخذني فغطني الثانية حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ فقلت ما أنا بقارئ‏.‏ فأخذني فغطني الثالثة، ثم أرسلني فقال ‏{‏اقرأ باسم ربك الذي خلق * خلق الإنسان من علق * اقرأ وربك الأكرم‏}‏ ‏\"‏‏.‏ فرجع بها رسول الله صلى الله عليه وسلم يرجف فؤاده، فدخل على خديجة بنت خويلد رضى الله عنها فقال ‏\"‏ زملوني زملوني ‏\"‏‏.‏ فزملوه حتى ذهب عنه الروع، فقال لخديجة وأخبرها الخبر ‏\"‏ لقد خشيت على نفسي ‏\"‏‏.‏ فقالت خديجة كلا والله ما يخزيك الله أبدا، إنك لتصل الرحم، وتحمل الكل، وتكسب المعدوم، وتقري الضيف، وتعين على نوائب الحق‏.‏ فانطلقت به خديجة حتى أتت به ورقة بن نوفل بن أسد بن عبد العزى ابن عم خديجة  وكان امرأ تنصر في الجاهلية، وكان يكتب الكتاب العبراني، فيكتب من الإنجيل بالعبرانية ما شاء الله أن يكتب، وكان شيخا كبيرا قد عمي  فقالت له خديجة يا ابن عم اسمع من ابن أخيك‏.‏ فقال له ورقة يا ابن أخي ماذا ترى فأخبره رسول الله صلى الله عليه وسلم خبر ما رأى‏.‏ فقال له ورقة هذا الناموس الذي نزل الله على موسى صلى الله عليه وسلم يا ليتني فيها جذعا، ليتني أكون حيا إذ يخرجك قومك‏.‏ فقال رسول الله صلى الله عليه وسلم ‏\"‏ أومخرجي هم ‏\"‏‏.‏ قال نعم، لم يأت رجل قط بمثل ما جئت به إلا عودي، وإن يدركني يومك أنصرك نصرا مؤزرا‏.‏ ثم لم ينشب ورقة أن توفي وفتر الوحى‏.‏   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        قال ابن شهاب وأخبرني أبو سلمة بن عبد الرحمن، أن جابر بن عبد الله الأنصاري، قال  وهو يحدث عن فترة الوحى، فقال  في حديثه ‏\"‏ بينا أنا أمشي، إذ سمعت صوتا، من السماء، فرفعت بصري فإذا الملك الذي جاءني بحراء جالس على كرسي بين السماء والأرض، فرعبت منه، فرجعت فقلت زملوني‏.‏ فأنزل الله تعالى ‏{‏يا أيها المدثر * قم فأنذر‏}‏ إلى قوله ‏{‏والرجز فاهجر‏}‏ فحمي الوحى وتتابع ‏\"‏‏.‏ تابعه عبد الله بن يوسف وأبو صالح‏.‏ وتابعه هلال بن رداد عن الزهري‏.‏ وقال يونس ومعمر ‏\"‏ بوادره ‏\"‏‏.‏   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      حدثنا موسى بن إسماعيل، قال حدثنا أبو عوانة، قال حدثنا موسى بن أبي عائشة، قال حدثنا سعيد بن جبير، عن ابن عباس، في قوله تعالى ‏{‏لا تحرك به لسانك لتعجل به‏}‏ قال كان رسول الله صلى الله عليه وسلم يعالج من التنزيل شدة، وكان مما يحرك شفتيه  فقال ابن عباس فأنا أحركهما لكم كما كان رسول الله صلى الله عليه وسلم يحركهما‏.‏ وقال سعيد أنا أحركهما كما رأيت ابن عباس يحركهما‏.‏ فحرك شفتيه  فأنزل الله تعالى ‏{‏لا تحرك به لسانك لتعجل به* إن علينا جمعه وقرآنه‏}‏ قال جمعه له في صدرك، وتقرأه ‏{‏فإذا قرأناه فاتبع قرآنه‏}‏ قال فاستمع له وأنصت ‏{‏ثم إن علينا بيانه‏}‏ ثم إن علينا أن تقرأه‏.‏ فكان رسول الله صلى الله عليه وسلم بعد ذلك إذا أتاه جبريل استمع، فإذا انطلق جبريل قرأه النبي صلى الله عليه وسلم كما قرأه‏.‏   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text_en  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Narrated 'Umar bin Al-Khattab:                          I heard Allah's Apostle saying, \"The reward of deeds depends upon the      intentions and every person will get the reward according to what he      has intended. So whoever emigrated for worldly benefits or for a woman     to marry, his emigration was for what he emigrated for.\"  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Narrated 'Aisha:                          (the mother of the faithful believers) Al-Harith bin Hisham asked Allah's Apostle \"O Allah's Apostle! How is the Divine Inspiration revealed to you?\" Allah's Apostle replied, \"Sometimes it is (revealed) like the ringing of a bell, this form of Inspiration is the hardest of all and then this state passes off after I have grasped what is inspired. Sometimes the Angel comes in the form of a man and talks to me and I grasp whatever he says.\" 'Aisha added: Verily I saw the Prophet being inspired divinely on a very cold day and noticed the sweat dropping from his forehead (as the Inspiration was over).  \n",
       "2   Narrated 'Aisha:                       (the mother of the faithful believers) The commencement of the Divine Inspiration to Allah's Apostle was in the form of good dreams which came true like bright daylight, and then the love of seclusion was bestowed upon him. He used to go in seclusion in the cave of Hira where he used to worship (Allah alone) continuously for many days before his desire to see his family. He used to take with him the journey food for the stay and then come back to (his wife) Khadija to take his food likewise again till suddenly the Truth descended upon him while he was in the cave of Hira. The angel came to him and asked him to read. The Prophet replied, \"I do not know how to read.\" The Prophet added, \"The angel caught me (forcefully) and pressed me so hard that I could not bear it any more. He then released me and again asked me to read and I replied, 'I do not know how to read.' Thereupon he caught me again and pressed me a second time till I could not bear it any more. He then released me and again asked me to read but again I replied, 'I do not know how to read (or what shall I read)?' Thereupon he caught me for the third time and pressed me, and then released me and said, 'Read in the name of your Lord, who has created (all that exists), created man from a clot. Read! And your Lord is the Most Generous.\" (96.1, 96.2, 96.3) Then Allah's Apostle returned with the Inspiration and with his heart beating severely. Then he went to Khadija bint Khuwailid and said, \"Cover me! Cover me!\" They covered him till his fear was over and after that he told her everything that had happened and said, \"I fear that something may happen to me.\" Khadija replied, \"Never! By Allah, Allah will never disgrace you. You keep good relations with your kith and kin, help the poor and the destitute, serve your guests generously and assist the deserving calamity-afflicted ones.\"  Khadija then accompanied him to her cousin Waraqa bin Naufal bin Asad bin 'Abdul 'Uzza, who, during the pre-Islamic Period became a Christian and used to write the writing with Hebrew letters. He would write from the Gospel in Hebrew as much as Allah wished him to write. He was an old man and had lost his eyesight. Khadija said to Waraqa, \"Listen to the story of your nephew, O my cousin!\" Waraqa asked, \"O my nephew! What have you seen?\" Allah's Apostle described whatever he had seen. Waraqa said, \"This is the same one who keeps the secrets (angel Gabriel) whom Allah had sent to Moses. I wish I were young and could live up to the time when your people would turn you out.\" Allah's Apostle asked, \"Will they drive me out?\" Waraqa replied in the affirmative and said, \"Anyone (man) who came with something similar to what you have brought was treated with hostility; and if I should remain alive till the day when you will be turned out then I would support you strongly.\" But after a few days Waraqa died and the Divine Inspiration was also paused for a while.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Narrated Jabir bin 'Abdullah Al-Ansari while talking about the period of pause in revelation reporting the speech of the Prophet \"While I was walking, all of a sudden I heard a voice from the sky. I looked up and saw the same angel who had visited me at the cave of Hira' sitting on a chair between the sky and the earth. I got afraid of him and came back home and said, 'Wrap me (in blankets).' And then Allah revealed the following Holy Verses (of Quran):                       'O you (i.e. Muhammad)! wrapped up in garments!' Arise and warn (the people against Allah's Punishment),... up to 'and desert the idols.' (74.1-5) After this the revelation started coming strongly, frequently and regularly.\"  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Narrated Said bin Jubair:                          Ibn 'Abbas in the explanation of the statement of Allah \"Move not your tongue concerning (the Quran) to make haste therewith.\" (75.16) said \"Allah's Apostle used to bear the revelation with great trouble and used to move his lips (quickly) with the Inspiration.\" Ibn 'Abbas moved his lips saying, \"I am moving my lips in front of you as Allah's Apostle used to move his.\" Said moved his lips saying: \"I am moving my lips, as I saw Ibn 'Abbas moving his.\" Ibn 'Abbas added, \"So Allah revealed 'Move not your tongue concerning (the Qur'an) to make haste therewith. It is for Us to collect it and to give you (O Muhammad) the ability to recite it (the Quran)' (75.16-17) which means that Allah will make him (the Prophet) remember the portion of the Qur'an which was revealed at that time by heart and recite it. The statement of Allah: 'And when we have recited it to you (O Muhammad through Gabriel) then you follow its (Quran) recital' (75.18) means 'listen to it and be silent.' Then it is for Us (Allah) to make it clear to you' (75.19) means 'Then it is (for Allah) to make you recite it (and its meaning will be clear by itself through your tongue). Afterwards, Allah's Apostle used to listen to Gabriel whenever he came and after his departure he used to recite it as Gabriel had recited it.\"  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadith_df = pd.read_csv(\"../data/hadith_dataset/all_hadiths_clean.csv\")\n",
    "hadith_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eab53a",
   "metadata": {},
   "source": [
    "Cogeremos las columnas (hadith-s) que nos interesan: `text_ar` y `text_en`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "650f0c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_ar    34433\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>حدثنا الحميدي عبد الله بن الزبير، قال حدثنا سفيان، قال حدثنا يحيى بن سعيد الأنصاري، قال أخبرني محمد بن إبراهيم التيمي، أنه سمع علقمة بن وقاص الليثي، يقول سمعت عمر بن الخطاب  رضى الله عنه  على المنبر قال سمعت رسول الله صلى الله عليه وسلم يقول ‏\"‏ إنما الأعمال بالنيات، وإنما لكل امرئ ما نوى، فمن كانت هجرته إلى دنيا يصيبها أو إلى امرأة ينكحها فهجرته إلى ما هاجر إليه ‏\"‏‏.‏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حدثنا عبد الله بن يوسف، قال أخبرنا مالك، عن هشام بن عروة، عن أبيه، عن عائشة أم المؤمنين  رضى الله عنها  أن الحارث بن هشام  رضى الله عنه  سأل رسول الله صلى الله عليه وسلم فقال يا رسول الله كيف يأتيك الوحى فقال رسول الله صلى الله عليه وسلم ‏\"‏ أحيانا يأتيني مثل صلصلة الجرس  وهو أشده على  فيفصم عني وقد وعيت عنه ما قال، وأحيانا يتمثل لي الملك رجلا فيكلمني فأعي ما يقول ‏\"‏‏.‏ قالت عائشة رضى الله عنها ولقد رأيته ينزل عليه الوحى في اليوم الشديد البرد، فيفصم عنه وإن جبينه ليتفصد عرقا‏.‏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حدثنا يحيى بن بكير، قال حدثنا الليث، عن عقيل، عن ابن شهاب، عن عروة بن الزبير، عن عائشة أم المؤمنين، أنها قالت أول ما بدئ به رسول الله صلى الله عليه وسلم من الوحى الرؤيا الصالحة في النوم، فكان لا يرى رؤيا إلا جاءت مثل فلق الصبح، ثم حبب إليه الخلاء، وكان يخلو بغار حراء فيتحنث فيه  وهو التعبد  الليالي ذوات العدد قبل أن ينزع إلى أهله، ويتزود لذلك، ثم يرجع إلى خديجة، فيتزود لمثلها، حتى جاءه الحق وهو في غار حراء، فجاءه الملك فقال اقرأ‏.‏ قال ‏\"‏ ما أنا بقارئ ‏\"‏‏.‏ قال ‏\"‏ فأخذني فغطني حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ قلت ما أنا بقارئ‏.‏ فأخذني فغطني الثانية حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ فقلت ما أنا بقارئ‏.‏ فأخذني فغطني الثالثة، ثم أرسلني فقال ‏{‏اقرأ باسم ربك الذي خلق * خلق الإنسان من علق * اقرأ وربك الأكرم‏}‏ ‏\"‏‏.‏ فرجع بها رسول الله صلى الله عليه وسلم يرجف فؤاده، فدخل على خديجة بنت خويلد رضى الله عنها فقال ‏\"‏ زملوني زملوني ‏\"‏‏.‏ فزملوه حتى ذهب عنه الروع، فقال لخديجة وأخبرها الخبر ‏\"‏ لقد خشيت على نفسي ‏\"‏‏.‏ فقالت خديجة كلا والله ما يخزيك الله أبدا، إنك لتصل الرحم، وتحمل الكل، وتكسب المعدوم، وتقري الضيف، وتعين على نوائب الحق‏.‏ فانطلقت به خديجة حتى أتت به ورقة بن نوفل بن أسد بن عبد العزى ابن عم خديجة  وكان امرأ تنصر في الجاهلية، وكان يكتب الكتاب العبراني، فيكتب من الإنجيل بالعبرانية ما شاء الله أن يكتب، وكان شيخا كبيرا قد عمي  فقالت له خديجة يا ابن عم اسمع من ابن أخيك‏.‏ فقال له ورقة يا ابن أخي ماذا ترى فأخبره رسول الله صلى الله عليه وسلم خبر ما رأى‏.‏ فقال له ورقة هذا الناموس الذي نزل الله على موسى صلى الله عليه وسلم يا ليتني فيها جذعا، ليتني أكون حيا إذ يخرجك قومك‏.‏ فقال رسول الله صلى الله عليه وسلم ‏\"‏ أومخرجي هم ‏\"‏‏.‏ قال نعم، لم يأت رجل قط بمثل ما جئت به إلا عودي، وإن يدركني يومك أنصرك نصرا مؤزرا‏.‏ ثم لم ينشب ورقة أن توفي وفتر الوحى‏.‏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>قال ابن شهاب وأخبرني أبو سلمة بن عبد الرحمن، أن جابر بن عبد الله الأنصاري، قال  وهو يحدث عن فترة الوحى، فقال  في حديثه ‏\"‏ بينا أنا أمشي، إذ سمعت صوتا، من السماء، فرفعت بصري فإذا الملك الذي جاءني بحراء جالس على كرسي بين السماء والأرض، فرعبت منه، فرجعت فقلت زملوني‏.‏ فأنزل الله تعالى ‏{‏يا أيها المدثر * قم فأنذر‏}‏ إلى قوله ‏{‏والرجز فاهجر‏}‏ فحمي الوحى وتتابع ‏\"‏‏.‏ تابعه عبد الله بن يوسف وأبو صالح‏.‏ وتابعه هلال بن رداد عن الزهري‏.‏ وقال يونس ومعمر ‏\"‏ بوادره ‏\"‏‏.‏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حدثنا موسى بن إسماعيل، قال حدثنا أبو عوانة، قال حدثنا موسى بن أبي عائشة، قال حدثنا سعيد بن جبير، عن ابن عباس، في قوله تعالى ‏{‏لا تحرك به لسانك لتعجل به‏}‏ قال كان رسول الله صلى الله عليه وسلم يعالج من التنزيل شدة، وكان مما يحرك شفتيه  فقال ابن عباس فأنا أحركهما لكم كما كان رسول الله صلى الله عليه وسلم يحركهما‏.‏ وقال سعيد أنا أحركهما كما رأيت ابن عباس يحركهما‏.‏ فحرك شفتيه  فأنزل الله تعالى ‏{‏لا تحرك به لسانك لتعجل به* إن علينا جمعه وقرآنه‏}‏ قال جمعه له في صدرك، وتقرأه ‏{‏فإذا قرأناه فاتبع قرآنه‏}‏ قال فاستمع له وأنصت ‏{‏ثم إن علينا بيانه‏}‏ ثم إن علينا أن تقرأه‏.‏ فكان رسول الله صلى الله عليه وسلم بعد ذلك إذا أتاه جبريل استمع، فإذا انطلق جبريل قرأه النبي صلى الله عليه وسلم كما قرأه‏.‏</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text_ar\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           حدثنا الحميدي عبد الله بن الزبير، قال حدثنا سفيان، قال حدثنا يحيى بن سعيد الأنصاري، قال أخبرني محمد بن إبراهيم التيمي، أنه سمع علقمة بن وقاص الليثي، يقول سمعت عمر بن الخطاب  رضى الله عنه  على المنبر قال سمعت رسول الله صلى الله عليه وسلم يقول ‏\"‏ إنما الأعمال بالنيات، وإنما لكل امرئ ما نوى، فمن كانت هجرته إلى دنيا يصيبها أو إلى امرأة ينكحها فهجرته إلى ما هاجر إليه ‏\"‏‏.‏\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            حدثنا عبد الله بن يوسف، قال أخبرنا مالك، عن هشام بن عروة، عن أبيه، عن عائشة أم المؤمنين  رضى الله عنها  أن الحارث بن هشام  رضى الله عنه  سأل رسول الله صلى الله عليه وسلم فقال يا رسول الله كيف يأتيك الوحى فقال رسول الله صلى الله عليه وسلم ‏\"‏ أحيانا يأتيني مثل صلصلة الجرس  وهو أشده على  فيفصم عني وقد وعيت عنه ما قال، وأحيانا يتمثل لي الملك رجلا فيكلمني فأعي ما يقول ‏\"‏‏.‏ قالت عائشة رضى الله عنها ولقد رأيته ينزل عليه الوحى في اليوم الشديد البرد، فيفصم عنه وإن جبينه ليتفصد عرقا‏.‏\n",
       "2  حدثنا يحيى بن بكير، قال حدثنا الليث، عن عقيل، عن ابن شهاب، عن عروة بن الزبير، عن عائشة أم المؤمنين، أنها قالت أول ما بدئ به رسول الله صلى الله عليه وسلم من الوحى الرؤيا الصالحة في النوم، فكان لا يرى رؤيا إلا جاءت مثل فلق الصبح، ثم حبب إليه الخلاء، وكان يخلو بغار حراء فيتحنث فيه  وهو التعبد  الليالي ذوات العدد قبل أن ينزع إلى أهله، ويتزود لذلك، ثم يرجع إلى خديجة، فيتزود لمثلها، حتى جاءه الحق وهو في غار حراء، فجاءه الملك فقال اقرأ‏.‏ قال ‏\"‏ ما أنا بقارئ ‏\"‏‏.‏ قال ‏\"‏ فأخذني فغطني حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ قلت ما أنا بقارئ‏.‏ فأخذني فغطني الثانية حتى بلغ مني الجهد، ثم أرسلني فقال اقرأ‏.‏ فقلت ما أنا بقارئ‏.‏ فأخذني فغطني الثالثة، ثم أرسلني فقال ‏{‏اقرأ باسم ربك الذي خلق * خلق الإنسان من علق * اقرأ وربك الأكرم‏}‏ ‏\"‏‏.‏ فرجع بها رسول الله صلى الله عليه وسلم يرجف فؤاده، فدخل على خديجة بنت خويلد رضى الله عنها فقال ‏\"‏ زملوني زملوني ‏\"‏‏.‏ فزملوه حتى ذهب عنه الروع، فقال لخديجة وأخبرها الخبر ‏\"‏ لقد خشيت على نفسي ‏\"‏‏.‏ فقالت خديجة كلا والله ما يخزيك الله أبدا، إنك لتصل الرحم، وتحمل الكل، وتكسب المعدوم، وتقري الضيف، وتعين على نوائب الحق‏.‏ فانطلقت به خديجة حتى أتت به ورقة بن نوفل بن أسد بن عبد العزى ابن عم خديجة  وكان امرأ تنصر في الجاهلية، وكان يكتب الكتاب العبراني، فيكتب من الإنجيل بالعبرانية ما شاء الله أن يكتب، وكان شيخا كبيرا قد عمي  فقالت له خديجة يا ابن عم اسمع من ابن أخيك‏.‏ فقال له ورقة يا ابن أخي ماذا ترى فأخبره رسول الله صلى الله عليه وسلم خبر ما رأى‏.‏ فقال له ورقة هذا الناموس الذي نزل الله على موسى صلى الله عليه وسلم يا ليتني فيها جذعا، ليتني أكون حيا إذ يخرجك قومك‏.‏ فقال رسول الله صلى الله عليه وسلم ‏\"‏ أومخرجي هم ‏\"‏‏.‏ قال نعم، لم يأت رجل قط بمثل ما جئت به إلا عودي، وإن يدركني يومك أنصرك نصرا مؤزرا‏.‏ ثم لم ينشب ورقة أن توفي وفتر الوحى‏.‏\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        قال ابن شهاب وأخبرني أبو سلمة بن عبد الرحمن، أن جابر بن عبد الله الأنصاري، قال  وهو يحدث عن فترة الوحى، فقال  في حديثه ‏\"‏ بينا أنا أمشي، إذ سمعت صوتا، من السماء، فرفعت بصري فإذا الملك الذي جاءني بحراء جالس على كرسي بين السماء والأرض، فرعبت منه، فرجعت فقلت زملوني‏.‏ فأنزل الله تعالى ‏{‏يا أيها المدثر * قم فأنذر‏}‏ إلى قوله ‏{‏والرجز فاهجر‏}‏ فحمي الوحى وتتابع ‏\"‏‏.‏ تابعه عبد الله بن يوسف وأبو صالح‏.‏ وتابعه هلال بن رداد عن الزهري‏.‏ وقال يونس ومعمر ‏\"‏ بوادره ‏\"‏‏.‏\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      حدثنا موسى بن إسماعيل، قال حدثنا أبو عوانة، قال حدثنا موسى بن أبي عائشة، قال حدثنا سعيد بن جبير، عن ابن عباس، في قوله تعالى ‏{‏لا تحرك به لسانك لتعجل به‏}‏ قال كان رسول الله صلى الله عليه وسلم يعالج من التنزيل شدة، وكان مما يحرك شفتيه  فقال ابن عباس فأنا أحركهما لكم كما كان رسول الله صلى الله عليه وسلم يحركهما‏.‏ وقال سعيد أنا أحركهما كما رأيت ابن عباس يحركهما‏.‏ فحرك شفتيه  فأنزل الله تعالى ‏{‏لا تحرك به لسانك لتعجل به* إن علينا جمعه وقرآنه‏}‏ قال جمعه له في صدرك، وتقرأه ‏{‏فإذا قرأناه فاتبع قرآنه‏}‏ قال فاستمع له وأنصت ‏{‏ثم إن علينا بيانه‏}‏ ثم إن علينا أن تقرأه‏.‏ فكان رسول الله صلى الله عليه وسلم بعد ذلك إذا أتاه جبريل استمع، فإذا انطلق جبريل قرأه النبي صلى الله عليه وسلم كما قرأه‏.‏"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadith_ar = hadith_df[\"text_ar\"]\n",
    "hadith_ar = pd.DataFrame(hadith_ar).dropna()\n",
    "\n",
    "hadith_ar.to_csv(\"../data/hadith_dataset/hadith_ar/hadith_ar.csv\", index=False, encoding=\"utf-8\")\n",
    "print(hadith_ar.count())\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "hadith_ar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a1bae",
   "metadata": {},
   "source": [
    "Función de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f448bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Conjunto de comillas comunes: \" ' y comillas tipográficas\n",
    "QUOTE_CHARS = r\"\\\"'“”„«»‹›`´\"\n",
    "\n",
    "def _strip_wrapping_quotes(text: str, max_loops: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Elimina comillas envolventes repetidas (incluyendo tipográficas),\n",
    "    tolerando espacios alrededor.\n",
    "    Ej:\n",
    "      '\"hola\"' -> hola\n",
    "      '  “hola”  ' -> hola\n",
    "      '\"\"hola\"\"' -> hola\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    t = text.strip()\n",
    "    for _ in range(max_loops):\n",
    "        # ^\\s*[\"'“”...]+ (captura comillas al inicio) y [\"'“”...]+\\s*$ (al final)\n",
    "        new_t = re.sub(rf'^\\s*[{QUOTE_CHARS}]+\\s*', '', t)\n",
    "        new_t = re.sub(rf'\\s*[{QUOTE_CHARS}]+\\s*$', '', new_t)\n",
    "        new_t = new_t.strip()\n",
    "        if new_t == t:\n",
    "            break\n",
    "        t = new_t\n",
    "    return t\n",
    "\n",
    "def clean_hadith_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "    text = _strip_wrapping_quotes(text)\n",
    "\n",
    "    text = text.replace('\"\"', '\"').lower()\n",
    "\n",
    "    # Limpieza del formato original del .csv: narrated by (nommbre del narrador) + texto que queremos\n",
    "    palabras_clave = (\n",
    "        r\"(said|asked|the|i\\s+heard|i\\s+was\\s+told|i\\s+informed|while|informed|abu|allah|\"\n",
    "        r\"if|when|once|some|whenever|it|sometimes|thereupon|then|and|but)\"\n",
    "    )\n",
    "    patron_narrador = r'^\\s*narrated\\s+.*?[:\\-]?\\s*(?=\\b' + palabras_clave + r'\\b)'\n",
    "    text = re.sub(patron_narrador, '', text).strip()\n",
    "\n",
    "    text = re.sub(rf'^\\s*[{QUOTE_CHARS}]+\\s*', '', text)\n",
    "    text = re.sub(rf'\\s*[{QUOTE_CHARS}]+\\s*$', '', text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,!?'\\-\\(\\)]\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d668f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_en = hadith_df[[\"text_en\"]].copy()\n",
    "\n",
    "hadith_en = hadith_en.dropna(subset=[\"text_en\"])\n",
    "\n",
    "# Quitamos la primera fila (texto no deseado)\n",
    "hadith_en = hadith_en.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "hadith_en[\"text_en\"] = hadith_en[\"text_en\"].apply(clean_hadith_text)\n",
    "\n",
    "hadith_en = hadith_en[hadith_en[\"text_en\"] != \"\"].reset_index(drop=True)\n",
    "\n",
    "output_path = \"../data/hadith_dataset/hadith_en/hadith_en_cleaned.csv\"\n",
    "\n",
    "hadith_en.to_csv(output_path, index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fed6af",
   "metadata": {},
   "source": [
    "Clase Dataset del Hadith dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb9bfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HadithDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, vectorizer: CoranVectorizer, text_col=\"text_en\"):\n",
    "        # text_col: text_en (hadith_en) y text_ar (hadith_ar)\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self._vectorizer = vectorizer\n",
    "        self._text_col = text_col\n",
    "        self._max_seq_length = min(int(self.df[text_col].astype(str).map(len).max()) + 2, 500)        \n",
    "        n = len(self.df)\n",
    "        train_end = int(n * 0.70) # 70% de las instancias al train set\n",
    "        val_end = int(n * .85) # 15 para el validation set, y el otro 15 para el test\n",
    "\n",
    "        self.train_df = self.df.iloc[:train_end]\n",
    "        self.val_df = self.df.iloc[train_end:val_end]\n",
    "        self.test_df = self.df.iloc[val_end:]\n",
    "\n",
    "        self._lookup_dict = {\n",
    "            \"train\": (self.train_df, len(self.train_df)),\n",
    "            \"val\": (self.val_df, len(self.val_df)),\n",
    "            \"test\": (self.test_df, len(self.test_df)),\n",
    "        }\n",
    "\n",
    "        self.set_split(\"train\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, hadith_csv, text_col):\n",
    "        df = pd.read_csv(hadith_csv)\n",
    "        # FIX: Use text_col instead of \"text\"\n",
    "        df[text_col] = df[text_col].astype(str).str.lower()\n",
    "        vectorizer = CoranVectorizer.from_dataframe(df, text_col)\n",
    "        return cls(df, vectorizer, text_col)\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, hadith_csv, vectorizer_filepath, text_col):\n",
    "        df = pd.read_csv(hadith_csv)\n",
    "        # FIX: Use text_col instead of \"text\"\n",
    "        df[text_col] = df[text_col].astype(str).str.lower()\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(df, vectorizer, text_col)\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            contents = json.load(f)\n",
    "        return CoranVectorizer.from_serializable(contents)\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self._vectorizer.to_serializable(), f, ensure_ascii=False)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "        text = str(row[self._text_col])\n",
    "        x, y = self._vectorizer.vectorize(text, vector_length=self._max_seq_length)\n",
    "        return {\"x_data\": torch.tensor(x, dtype=torch.long), \"y_target\": torch.tensor(y, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858bdd6",
   "metadata": {},
   "source": [
    "Empezamos el entrenamiento con el dataset de Hadith-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d861401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN():\n",
    "    args = Namespace(\n",
    "        hadith_csv=\"../data/hadith_dataset/hadith_en/hadith_en_cleaned.csv\",\n",
    "        vectorizer_file=\"vectorizer.json\",\n",
    "        model_state_file=\"model.pth\",\n",
    "        save_dir=\"Unai/Models/RNN/hadith/coran_rnn_v1\",\n",
    "\n",
    "        char_embedding_size=300, # 300 porque los embeddings del ft son de 300, tienen que coincidir\n",
    "        rnn_hidden_size=128, # 256-ekin peatau itenzatek\n",
    "\n",
    "        seed=1337,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=256,\n",
    "        num_epochs=50,\n",
    "        early_stopping_criteria=5,\n",
    "\n",
    "        cuda=True,\n",
    "        reload_from_files=False\n",
    "    )\n",
    "\n",
    "    print(args.batch_size)\n",
    "\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda and torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        args.device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        args.device = torch.device(\"cpu\")\n",
    "\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    if args.vectorizer_file and not os.path.isabs(args.vectorizer_file):\n",
    "        args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "    if args.model_state_file and not os.path.isabs(args.model_state_file):\n",
    "        args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "    if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "        dataset = HadithDataset.load_dataset_and_load_vectorizer(args.hadith_csv, args.vectorizer_file, \"text_en\")\n",
    "    else:\n",
    "        dataset = HadithDataset.load_dataset_and_make_vectorizer(args.hadith_csv, \"text_en\")\n",
    "        dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "    vectorizer = dataset.get_vectorizer()\n",
    "    mask_index = vectorizer.char_vocab.mask_index\n",
    "\n",
    "    def obtener_pesos(vectorizer, modelo_ft):\n",
    "        vocab = vectorizer.char_vocab\n",
    "        token_to_idx = vocab._token_to_idx\n",
    "        tamaño_vocab = len(token_to_idx)\n",
    "        embedding_dim = modelo_ft.get_dimension()\n",
    "        pesos = np.zeros((tamaño_vocab, embedding_dim))\n",
    "\n",
    "        for token, idx in token_to_idx.items():\n",
    "            pesos[idx] = modelo_ft.get_word_vector(token)\n",
    "    \n",
    "        return torch.FloatTensor(pesos)\n",
    "\n",
    "    ft_ingles = fasttext.load_model(\"../src/modelos/fasttext_english_busqueda_seamantica.bin\")\n",
    "    pretrained_ft_pesos = obtener_pesos(vectorizer, ft_ingles)\n",
    "\n",
    "    model = CoranRNN(\n",
    "        vocab_size=len(vectorizer.char_vocab),\n",
    "        embedding_size=args.char_embedding_size,\n",
    "        rnn_hidden_size=args.rnn_hidden_size,\n",
    "        padding_idx=mask_index,\n",
    "        pretrained_embeddings_ft=pretrained_ft_pesos\n",
    "    ).to(args.device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "    train_state = make_train(args)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_state[\"epoch_index\"] = epoch\n",
    "\n",
    "        # Train\n",
    "        dataset.set_split(\"train\")\n",
    "        model.train()\n",
    "        running_loss, running_acc = 0.0, 0.0\n",
    "        for bi, batch in enumerate(generate_batches(dataset, args.batch_size, args.device, shuffle=True)):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch[\"x_data\"])\n",
    "            loss = sequence_loss(y_pred, batch[\"y_target\"], mask_index)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += (loss.item() - running_loss) / (bi + 1)\n",
    "            acc = compute_accuracy(y_pred, batch[\"y_target\"], mask_index)\n",
    "            running_acc += (acc - running_acc) / (bi + 1)\n",
    "\n",
    "        train_state[\"train_loss\"].append(running_loss)\n",
    "        train_state[\"train_acc\"].append(running_acc)\n",
    "\n",
    "        # Val\n",
    "        dataset.set_split(\"val\")\n",
    "        model.eval()\n",
    "        vloss, vacc = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for bi, batch in enumerate(generate_batches(dataset, args.batch_size, args.device, shuffle=False)):\n",
    "                y_pred = model(batch[\"x_data\"])\n",
    "                loss = sequence_loss(y_pred, batch[\"y_target\"], mask_index)\n",
    "\n",
    "                vloss += (loss.item() - vloss) / (bi + 1)\n",
    "                acc = compute_accuracy(y_pred, batch[\"y_target\"], mask_index)\n",
    "                vacc += (acc - vacc) / (bi + 1)\n",
    "\n",
    "        train_state[\"val_loss\"].append(vloss)\n",
    "        train_state[\"val_acc\"].append(vacc)\n",
    "\n",
    "        train_state = update_training_state(args, model, train_state)\n",
    "        scheduler.step(vloss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | train_loss={running_loss:.4f} \"\n",
    "              f\"| val_loss={vloss:.4f} | val_acc={vacc:.4f}\")\n",
    "        \n",
    "        dataset.save_vectorizer(args.vectorizer_file)\n",
    "        torch.save(model.state_dict(), args.model_state_file)\n",
    "\n",
    "        if train_state[\"stop_early\"]:\n",
    "            print(\"Early stopping activado.\")\n",
    "            break\n",
    "\n",
    "    return args, dataset, vectorizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0066b9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=2.8241 | val_loss=2.3093 | val_acc=0.3470\n",
      "Epoch 002 | train_loss=2.2620 | val_loss=2.0432 | val_acc=0.4160\n",
      "Epoch 003 | train_loss=2.0805 | val_loss=1.8840 | val_acc=0.4769\n",
      "Epoch 004 | train_loss=1.9622 | val_loss=1.7745 | val_acc=0.4997\n",
      "Epoch 005 | train_loss=1.8833 | val_loss=1.7060 | val_acc=0.5103\n",
      "Epoch 006 | train_loss=1.8312 | val_loss=1.6579 | val_acc=0.5246\n",
      "Epoch 007 | train_loss=1.7942 | val_loss=1.6244 | val_acc=0.5348\n",
      "Epoch 008 | train_loss=1.7660 | val_loss=1.5998 | val_acc=0.5418\n",
      "Epoch 009 | train_loss=1.7438 | val_loss=1.5799 | val_acc=0.5440\n",
      "Epoch 010 | train_loss=1.7252 | val_loss=1.5609 | val_acc=0.5514\n",
      "Epoch 011 | train_loss=1.7095 | val_loss=1.5480 | val_acc=0.5551\n",
      "Epoch 012 | train_loss=1.6973 | val_loss=1.5351 | val_acc=0.5594\n",
      "Epoch 013 | train_loss=1.6858 | val_loss=1.5284 | val_acc=0.5601\n",
      "Epoch 014 | train_loss=1.6761 | val_loss=1.5202 | val_acc=0.5633\n",
      "Epoch 015 | train_loss=1.6682 | val_loss=1.5119 | val_acc=0.5658\n",
      "Epoch 016 | train_loss=1.6605 | val_loss=1.5059 | val_acc=0.5659\n",
      "Epoch 017 | train_loss=1.6536 | val_loss=1.5002 | val_acc=0.5695\n",
      "Epoch 018 | train_loss=1.6475 | val_loss=1.4954 | val_acc=0.5693\n",
      "Epoch 019 | train_loss=1.6421 | val_loss=1.4894 | val_acc=0.5712\n",
      "Epoch 020 | train_loss=1.6374 | val_loss=1.4862 | val_acc=0.5719\n",
      "Epoch 021 | train_loss=1.6330 | val_loss=1.4823 | val_acc=0.5743\n",
      "Epoch 022 | train_loss=1.6285 | val_loss=1.4779 | val_acc=0.5744\n",
      "Epoch 023 | train_loss=1.6248 | val_loss=1.4753 | val_acc=0.5761\n",
      "Epoch 024 | train_loss=1.6216 | val_loss=1.4719 | val_acc=0.5773\n",
      "Epoch 025 | train_loss=1.6177 | val_loss=1.4681 | val_acc=0.5780\n",
      "Epoch 026 | train_loss=1.6147 | val_loss=1.4642 | val_acc=0.5789\n",
      "Epoch 027 | train_loss=1.6119 | val_loss=1.4623 | val_acc=0.5820\n",
      "Epoch 028 | train_loss=1.6091 | val_loss=1.4601 | val_acc=0.5834\n",
      "Epoch 029 | train_loss=1.6066 | val_loss=1.4571 | val_acc=0.5842\n",
      "Epoch 030 | train_loss=1.6044 | val_loss=1.4578 | val_acc=0.5792\n",
      "Epoch 031 | train_loss=1.6024 | val_loss=1.4546 | val_acc=0.5818\n",
      "Epoch 032 | train_loss=1.5999 | val_loss=1.4521 | val_acc=0.5828\n",
      "Epoch 033 | train_loss=1.5981 | val_loss=1.4525 | val_acc=0.5810\n",
      "Epoch 034 | train_loss=1.5962 | val_loss=1.4517 | val_acc=0.5827\n",
      "Epoch 035 | train_loss=1.5947 | val_loss=1.4507 | val_acc=0.5801\n",
      "Epoch 036 | train_loss=1.5931 | val_loss=1.4473 | val_acc=0.5838\n",
      "Epoch 037 | train_loss=1.5915 | val_loss=1.4491 | val_acc=0.5842\n",
      "Epoch 038 | train_loss=1.5897 | val_loss=1.4463 | val_acc=0.5815\n",
      "Epoch 039 | train_loss=1.5890 | val_loss=1.4460 | val_acc=0.5812\n",
      "Epoch 040 | train_loss=1.5876 | val_loss=1.4425 | val_acc=0.5841\n",
      "Epoch 041 | train_loss=1.5867 | val_loss=1.4427 | val_acc=0.5851\n",
      "Epoch 042 | train_loss=1.5854 | val_loss=1.4419 | val_acc=0.5832\n",
      "Epoch 043 | train_loss=1.5846 | val_loss=1.4421 | val_acc=0.5863\n",
      "Epoch 044 | train_loss=1.5831 | val_loss=1.4412 | val_acc=0.5833\n",
      "Epoch 045 | train_loss=1.5822 | val_loss=1.4406 | val_acc=0.5857\n",
      "Epoch 046 | train_loss=1.5818 | val_loss=1.4416 | val_acc=0.5834\n",
      "Epoch 047 | train_loss=1.5804 | val_loss=1.4386 | val_acc=0.5868\n",
      "Epoch 048 | train_loss=1.5794 | val_loss=1.4402 | val_acc=0.5839\n",
      "Epoch 049 | train_loss=1.5778 | val_loss=1.4406 | val_acc=0.5839\n",
      "Epoch 050 | train_loss=1.5761 | val_loss=1.4366 | val_acc=0.5874\n"
     ]
    }
   ],
   "source": [
    "args, dataset, vectorizer, model_rnn = train_RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b1dfd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "\n",
      " Verse 1:\n",
      "the propans and the same not of puraing with the is replaining tall o eros (lever and ont corneasting aponthto said i had the andar to the shares of that a sabdo chitode of the prophet ( ) seed fill in the versed comes theres) wall coured untin task bisk.\n",
      "\n",
      " Verse 2:\n",
      "abamfaranm m and the for upen oneren)\n",
      "\n",
      " Verse 3:\n",
      "abu huraira wat'lat thet was chatered, the informed and in me the messengor (whing the ponfited to the fristy in allah's mind betreced to him in the there of the prophet ( ) man and allah as the tereisers, i promelsand ibn iljat abna mat 'romins the mendared. bethe de in who perestle of nurdes of th\n",
      "\n",
      " Verse 4:\n",
      "amal said (nasill and like nien say by allah's has the arearill belpen, in me and the fiss of allah, bedren josishen mots and the enters and him to whaling of not he said, ol al-sahima ha (messafiled an abrathe (of alllahab, b. al-muthal has not fitt the destle of al- am arrangither i comen. thereri\n",
      "\n",
      " Verse 5:\n",
      "alia had a wah we porting is the was seed his prophet. upan, is the came and the lerse of him of the complissiti eqasing water, she purera the prophet (may peace be upon haf he about the batters of the place of the salim t mwosender and h. soalle the insher shing and we seen allah me muthing, but th\n",
      "\n",
      " Verse 6:\n",
      "the messenger of allah ( ) sa dithiss of saham, lale revealed it, when the prophet shall be parasisity of allah with the same for the messenger and of the last had bnolsenght with his was of eather the boid if enter wesion would from the prophet (a) the messenger of allah dinsee of allah's melsees b\n",
      "\n",
      " Verse 7:\n",
      "abu hurtam in the rakisa bo shall reporse conters) said his versen) in ith in me thriod, (moting of thicd an and a gey of 'isk the messenger of allah ( ) said for and the asesen your. do the prophet says, and will shithan said when he was and said, allamarr. when you disserence in for umigh your tom\n",
      "\n",
      " Verse 8:\n",
      "allah's aposthedded the chatior (from ler and with the dould. i came ot sict used to much an one allishish where the messenger of allah (may peed. (qure.\n",
      "\n",
      " Verse 9:\n",
      "ait batt the prophet (al-ksabun said for a ther had the with used to messenger of allah (may peace be upon him) was if eren sof safin for you wsily allharre seef saled, and de the messenger of allah ( ) said me and sowed the prophet. a sabd of lell fild not the prophet and have the had that he made \n",
      "\n",
      " Verse 10:\n",
      "the surhen sacked the faring in the of ander of anthatoud to top, we hight water of the folleardidered abdadd be). the prophet (may peace be upon he was her propent the messenger of allah said the messenger of allah (may peace be mulbana, and we dither in the prophet ( ) said the messenger of allah \n"
     ]
    }
   ],
   "source": [
    "# number of verses to generate\n",
    "num_names = 10\n",
    "\n",
    "model = model_rnn.cpu()\n",
    "\n",
    "sampled_verses = decode_samples(\n",
    "    sample_from_model(\n",
    "        model,\n",
    "        vectorizer,\n",
    "        num_samples=num_names,\n",
    "        max_length=300,\n",
    "        temperature=0.8\n",
    "    ),\n",
    "    vectorizer\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(\"-\" * 30)\n",
    "for i in range(num_names):\n",
    "    print(f\"\\n Verse {i+1}:\\n{sampled_verses[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coran-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
