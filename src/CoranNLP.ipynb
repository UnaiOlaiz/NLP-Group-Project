{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5909b17",
   "metadata": {},
   "source": [
    "# Libererías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83dc8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980cbf4",
   "metadata": {},
   "source": [
    "# Análisis del Quran en Árabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabf1d1",
   "metadata": {},
   "source": [
    "Primero importamos el dataset que hemos limpiado con la función anteriormente creada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b005d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|1|بسم الله الرحمن الرحيم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|2|الحمد لله رب العالمين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1|3|الرحمن الرحيم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1|4|مالك يوم الدين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1|5|اياك نعبد واياك نستعين</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text\n",
       "0  1|1|بسم الله الرحمن الرحيم\n",
       "1   1|2|الحمد لله رب العالمين\n",
       "2           1|3|الرحمن الرحيم\n",
       "3          1|4|مالك يوم الدين\n",
       "4  1|5|اياك نعبد واياك نستعين"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/cleaned_data/cleaned_arab_quran.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "df = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].str.strip()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0f2b4",
   "metadata": {},
   "source": [
    "Importamos el sentence-transformer que vamos a usar para ambos idiomas, ya que éste es multilingüe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0a687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968851b6b4174ed2a2c3475e7915db02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db3f85dbb0443b69d208cf046212b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe0aa2330304fc793b6569554030a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac263bc16e84ee892a4698789e6a541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baa279ba4e04237a16a322ae2429ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6350595d4053473dafdd095ef5929339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812f491f7f7641cdab43b9d2c06fc22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97c631f8add434d9a36d2b372a6ebe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5897b1c57ea642b4b6f94de53a35a617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460b6b9820ad48cb9ed23eef63750e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9365b8e050b54baa9b2aa533bec4412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Y si usamos fastText? Proguntar a Miguel y a Unai porque ha decidido usar sentence transformers\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe9b2b",
   "metadata": {},
   "source": [
    "Y ahora creamos los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b84712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"arab_embeddings\"] = df[\"text\"].apply(lambda x: model.encode(x, convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421ef08",
   "metadata": {},
   "source": [
    "Now we can see the applied arab embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ec230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>arab_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|1|بسم الله الرحمن الرحيم</td>\n",
       "      <td>[tensor(-0.0018), tensor(0.0619), tensor(-0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|2|الحمد لله رب العالمين</td>\n",
       "      <td>[tensor(0.0052), tensor(0.0776), tensor(-0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1|3|الرحمن الرحيم</td>\n",
       "      <td>[tensor(0.0033), tensor(0.0738), tensor(0.0118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1|4|مالك يوم الدين</td>\n",
       "      <td>[tensor(0.0616), tensor(0.1301), tensor(0.0168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1|5|اياك نعبد واياك نستعين</td>\n",
       "      <td>[tensor(-0.0151), tensor(0.0704), tensor(-0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text  \\\n",
       "0  1|1|بسم الله الرحمن الرحيم   \n",
       "1   1|2|الحمد لله رب العالمين   \n",
       "2           1|3|الرحمن الرحيم   \n",
       "3          1|4|مالك يوم الدين   \n",
       "4  1|5|اياك نعبد واياك نستعين   \n",
       "\n",
       "                                     arab_embeddings  \n",
       "0  [tensor(-0.0018), tensor(0.0619), tensor(-0.03...  \n",
       "1  [tensor(0.0052), tensor(0.0776), tensor(-0.006...  \n",
       "2  [tensor(0.0033), tensor(0.0738), tensor(0.0118...  \n",
       "3  [tensor(0.0616), tensor(0.1301), tensor(0.0168...  \n",
       "4  [tensor(-0.0151), tensor(0.0704), tensor(-0.01...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b2073",
   "metadata": {},
   "source": [
    "Ahora probamos la búsqueda semántica por concepto, vamos a usar la similitud de coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0459583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  cos_similarity\n",
      "5600          76|10|انا نخاف من ربنا يوما عبوسا قمطريرا        0.218459\n",
      "279   2|273|للفقراء الذين احصروا في سبيل الله لا يست...        0.217785\n",
      "2535                21|53|قالوا وجدنا اباءنا لها عابدين        0.215674\n",
      "6236                                                           0.213338\n",
      "6237                                                           0.213338\n",
      "5879             83|32|واذا راوهم قالوا ان هؤلاء لضالون        0.209789\n",
      "3227  27|69|قل سيروا في الارض فانظروا كيف كان عاقبه ...        0.208556\n",
      "3532               32|30|فاعرض عنهم وانتظر انهم منتظرون        0.207411\n",
      "1548  11|76|يا ابراهيم اعرض عن هذا ۖ انه قد جاء امر ...        0.204135\n",
      "5621  76|31|يدخل من يشاء في رحمته ۚ والظالمين اعد له...        0.202699\n"
     ]
    }
   ],
   "source": [
    "concept = \"Paradise\" # por ejemplo\n",
    "concept_emb = model.encode(concept.lower(), convert_to_tensor=True)\n",
    "\n",
    "df[\"cos_similarity\"] = df[\"arab_embeddings\"].apply(lambda x: util.pytorch_cos_sim(x, concept_emb).item())\n",
    "df_sorted = df.sort_values(by=\"cos_similarity\", ascending=False)\n",
    "print(pd.DataFrame(df_sorted[[\"text\", \"cos_similarity\"]].head(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f8c07",
   "metadata": {},
   "source": [
    "# Análisis de Quran en Inglés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f05723",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/unaiolaizolaosa/Dokumentuak/NLP-Group-Project/data/cleaned_data/cleaned_english_quran.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "df = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].str.strip()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3189741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"arab_embeddings\"] = df[\"text\"].apply(lambda x: model.encode(x, convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "983b63ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  cos_similarity\n",
      "6022                              and enter my paradise        0.638474\n",
      "4394        enter paradise you and your kinds delighted        0.631074\n",
      "5812                  and when paradise is brought near        0.614703\n",
      "2878  the companions of paradise that day are in a b...        0.591378\n",
      "4559  is the description of paradise which the right...        0.576164\n",
      "5610  and when you look there in paradise you will s...        0.570232\n",
      "4660  and paradise will be brought near to the right...        0.556255\n",
      "4396  and that is paradise which you are made to inh...        0.549605\n",
      "3021  and paradise will be brought near that day to ...        0.535889\n",
      "615   paradise is not obtained by your wishful think...        0.533608\n"
     ]
    }
   ],
   "source": [
    "concept = \"Paradise\" # por ejemplo\n",
    "concept_emb = model.encode(concept.lower(), convert_to_tensor=True)\n",
    "\n",
    "df[\"cos_similarity\"] = df[\"arab_embeddings\"].apply(lambda x: util.pytorch_cos_sim(x, concept_emb).item())\n",
    "df_sorted = df.sort_values(by=\"cos_similarity\", ascending=False)\n",
    "print(df_sorted[[\"text\", \"cos_similarity\"]].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coran-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
