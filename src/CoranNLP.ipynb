{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5909b17",
   "metadata": {},
   "source": [
    "# Libererías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83dc8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import fasttext\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980cbf4",
   "metadata": {},
   "source": [
    "# Análisis del Quran en Árabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabf1d1",
   "metadata": {},
   "source": [
    "Primero importamos el dataset que hemos limpiado con la función anteriormente creada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b005d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|1|بسم الله الرحمن الرحيم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|2|الحمد لله رب العالمين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1|3|الرحمن الرحيم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1|4|مالك يوم الدين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1|5|اياك نعبد واياك نستعين</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text\n",
       "0  1|1|بسم الله الرحمن الرحيم\n",
       "1   1|2|الحمد لله رب العالمين\n",
       "2           1|3|الرحمن الرحيم\n",
       "3          1|4|مالك يوم الدين\n",
       "4  1|5|اياك نعبد واياك نستعين"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/cleaned_data/cleaned_arab_quran.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "df = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].str.strip()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9ac38",
   "metadata": {},
   "source": [
    "Ahora vamos a usar 2 modelos diferentes para comparar los resultados, usaremos el concepto \"الجنة\" (paraíso) para ambas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe57e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = \"الجنة\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0f2b4",
   "metadata": {},
   "source": [
    "Importamos el sentence-transformer que vamos a usar para ambos idiomas, ya que éste es multilingüe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae28d42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806d3dd4d032477e88829aca61254c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7ae2b6b1294cf8b3bc9f2e79955c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9da666988d44a37b47340d847b964d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecce07ef4af94ca797ab28e8243934fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb42b42d21146e985018937f1951dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c0b3a2670a40fbb526e761adb45f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16b7e446047400589d925d9c2fa40a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687529248b4f4498a9aefb6e23d36238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46092d2442314604b05d6103cd934199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6488a00651264d528daa925bbaae783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe2484155bc47258649c3266971cefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7359f06eed34fa0964ce8ae82dea589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7132267ce8e944b7b0062d79e523c187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Sentence-Transformers:\n",
      "                                                text  cos_similarity\n",
      "0                         1|1|بسم الله الرحمن الرحيم        0.471993\n",
      "5475      73|1|بسم الله الرحمن الرحيم يا ايها المزمل        0.427254\n",
      "7                     2|1|بسم الله الرحمن الرحيم الم        0.420491\n",
      "293                   3|1|بسم الله الرحمن الرحيم الم        0.410380\n",
      "294               3|2|الله لا اله الا هو الحي القيوم        0.404758\n",
      "5377                         70|3|من الله ذي المعارج        0.404345\n",
      "4133                  40|1|بسم الله الرحمن الرحيم حم        0.402066\n",
      "1                          1|2|الحمد لله رب العالمين        0.399989\n",
      "5495      74|1|بسم الله الرحمن الرحيم يا ايها المدثر        0.397255\n",
      "5909  85|1|بسم الله الرحمن الرحيم والسماء ذات البروج        0.390075\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "df_st = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df_st[\"text\"] = df_st[\"text\"].str.strip()\n",
    "df_st = df_st[df_st[\"text\"].str.contains(r\"[\\u0600-\\u06FF]\")]\n",
    "df_st[\"arab_embeddings\"] = df_st[\"text\"].apply(lambda x: model.encode(x, convert_to_tensor=True))\n",
    "\n",
    "concept_emb = model.encode(concept, convert_to_tensor=True)\n",
    "\n",
    "df_st[\"cos_similarity\"] = df_st[\"arab_embeddings\"].apply(lambda x: util.pytorch_cos_sim(x, concept_emb).item())\n",
    "\n",
    "df_st_sorted = df_st.sort_values(by=\"cos_similarity\", ascending=False)\n",
    "print(\"\\nTop 10 Sentence-Transformers:\")\n",
    "print(df_st_sorted[[\"text\", \"cos_similarity\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2fc84",
   "metadata": {},
   "source": [
    "Ahora probaremos el mismo proceso con el modelo recomendado por nuestro profesor: 'fastText'. Como se verá en los hiperparámetros, las sub palabras hacen referencia a N-gramas de caracteres, es decir, caracteres de entre 3 a 6 letras. (hay que tener en cuenta que a diferencia de sentence-transformer, fast text devuelve vectores Numpy, y no vectores PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff48ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  2016\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   70101 lr:  0.000000 avg.loss:  2.555924 ETA:   0h 0m 0s 67.8% words/sec/thread:   71175 lr:  0.016119 avg.loss:  2.633729 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 FastText:\n",
      "                                                   text  cos_similarity\n",
      "5815                                 81|16|الجوار الكنس        0.922746\n",
      "4986               56|8|فاصحاب الميمنه ما اصحاب الميمنه        0.889601\n",
      "4987               56|9|واصحاب المشامه ما اصحاب المشامه        0.884195\n",
      "5019                56|41|واصحاب الشمال ما اصحاب الشمال        0.876312\n",
      "5752                          79|41|فان الجنه هي الماوي        0.876007\n",
      "1862                     15|61|فلما جاء ال لوط المرسلون        0.859562\n",
      "5750                         79|39|فان الجحيم هي الماوي        0.858952\n",
      "3927                    37|140|اذ ابق الي الفلك المشحون        0.853208\n",
      "3917                           37|130|سلام علي ال ياسين        0.846132\n",
      "2553  21|71|ونجيناه ولوطا الي الارض التي باركنا فيها...        0.835405\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.train_unsupervised(\n",
    "    input=\"../data/cleaned_data/cleaned_arab_quran.txt\",\n",
    "    model=\"skipgram\",\n",
    "    dim=300,\n",
    "    epoch=10,\n",
    "    minn=3,  # sub palabras mínimas\n",
    "    maxn=6   # sub palabras máximas\n",
    ")\n",
    "\n",
    "df_ft = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df_ft[\"text\"] = df_ft[\"text\"].str.strip()\n",
    "df_ft = df_ft[df_ft[\"text\"].str.contains(r\"[\\u0600-\\u06FF]\")]\n",
    "\n",
    "df_ft[\"arab_embeddings\"] = df_ft[\"text\"].apply(lambda x: ft.get_sentence_vector(x))\n",
    "\n",
    "concept_emb = ft.get_sentence_vector(concept)\n",
    "\n",
    "df_ft[\"cos_similarity\"] = df_ft[\"arab_embeddings\"].apply(\n",
    "    lambda x: cosine_similarity([x], [concept_emb])[0][0]\n",
    ")\n",
    "\n",
    "df_ft_sorted = df_ft.sort_values(by=\"cos_similarity\", ascending=False)\n",
    "print(\"Top 10 FastText:\")\n",
    "print(df_ft_sorted[[\"text\", \"cos_similarity\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f8c07",
   "metadata": {},
   "source": [
    "# Análisis de Quran en Inglés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0f05723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the name of allah the entirely merciful the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all praise is due to allah lord of the worlds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the entirely merciful the especially merciful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sovereign of the day of recompense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it is you we worship and you we ask for help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  in the name of allah the entirely merciful the...\n",
       "1      all praise is due to allah lord of the worlds\n",
       "2      the entirely merciful the especially merciful\n",
       "3                 sovereign of the day of recompense\n",
       "4       it is you we worship and you we ask for help"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/cleaned_data/cleaned_english_quran.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "df = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].str.strip()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e24574f",
   "metadata": {},
   "source": [
    "Repetiremos el mismo proceso para el Corán en inglés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bb5b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = \"Paradise\" # el mismo que antes, pero ahora en inglés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed03737",
   "metadata": {},
   "source": [
    "Sentence-transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f3cd122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Sentence-Transformers:\n",
      "                                             text  cos_similarity\n",
      "6022                        and enter my paradise        0.519508\n",
      "6232                           the god of mankind        0.502047\n",
      "6222                     allah the eternal refuge        0.500632\n",
      "5812            and when paradise is brought near        0.445605\n",
      "4681            by the heaven containing pathways        0.439895\n",
      "2348                                        ta ha        0.434508\n",
      "5752      then indeed paradise will be his refuge        0.432990\n",
      "4739                and by the heaven raised high        0.432732\n",
      "5820  obeyed there in the heavens and trustworthy        0.430074\n",
      "5630                and when the heaven is opened        0.409571\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "df_st = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df_st[\"text\"] = df_st[\"text\"].str.strip()\n",
    "df_st = df_st[df_st[\"text\"].str.len() > 0]\n",
    "df_st[\"eng_embeddings\"] = df_st[\"text\"].apply(lambda x: model.encode(x, convert_to_tensor=True))\n",
    "\n",
    "concept_emb = model.encode(concept, convert_to_tensor=True)\n",
    "\n",
    "df_st[\"cos_similarity\"] = df_st[\"eng_embeddings\"].apply(lambda x: util.pytorch_cos_sim(x, concept_emb).item())\n",
    "\n",
    "df_st_sorted = df_st.sort_values(by=\"cos_similarity\", ascending=False)\n",
    "print(\"\\nTop 10 Sentence-Transformers:\")\n",
    "print(df_st_sorted[[\"text\", \"cos_similarity\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4840ed",
   "metadata": {},
   "source": [
    "FastText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6405405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  1924\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   77969 lr:  0.000000 avg.loss:  2.549588 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 FastText:\n",
      "                                                   text  cos_similarity\n",
      "4019  gardens of perpetual residence whose doors wil...        0.835064\n",
      "6022                              and enter my paradise        0.827785\n",
      "2683  who will inherit al firdaus they will abide th...        0.827519\n",
      "549   but those who believe and do righteous deeds w...        0.823820\n",
      "1772  and those who believed and did righteous deeds...        0.819989\n",
      "1931  gardens of perpetual residence which they will...        0.815658\n",
      "2423  gardens of perpetual residence beneath which r...        0.814887\n",
      "2617  indeed allah will admit those who believe and ...        0.808613\n",
      "1323  allah has prepared for them gardens beneath wh...        0.802673\n",
      "3397  and those who have believed and done righteous...        0.801086\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.train_unsupervised(\n",
    "    input=\"../data/cleaned_data/cleaned_english_quran.txt\",\n",
    "    model=\"skipgram\",\n",
    "    dim=300,\n",
    "    epoch=10,\n",
    "    minn=3,  # sub palabras mínimas\n",
    "    maxn=6   # sub palabras máximas\n",
    ")\n",
    "\n",
    "df_ft = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df_ft[\"text\"] = df_ft[\"text\"].str.strip()\n",
    "\n",
    "df_ft[\"eng_embeddings\"] = df_ft[\"text\"].apply(lambda x: ft.get_sentence_vector(x))\n",
    "\n",
    "concept_emb = ft.get_sentence_vector(concept)\n",
    "\n",
    "df_ft[\"cos_similarity\"] = df_ft[\"eng_embeddings\"].apply(\n",
    "    lambda x: cosine_similarity([x], [concept_emb])[0][0]\n",
    ")\n",
    "\n",
    "df_ft_sorted = df_ft.sort_values(by=\"cos_similarity\", ascending=False)\n",
    "print(\"Top 10 FastText:\")\n",
    "print(df_ft_sorted[[\"text\", \"cos_similarity\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c1f0d",
   "metadata": {},
   "source": [
    "# Resultados después de la comparación:\n",
    "Después de tratar con ambos idiomas y los 2 modelos, y ver que ambos devuelven pasajes similares, concluimos con que hay una diferencia abismal en cuanto a la similitud de coseno. Ya que el modelo 'fastText' obtiene mejores resultados. Por esa razón y por la recomendación del profesor, hemos decidido quedarnos con este modelo para más adelante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coran-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
